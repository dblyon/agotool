{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dblyon/modules/cpr/agotool'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dblyon/modules/cpr/agotool/app/python\n"
     ]
    }
   ],
   "source": [
    "cd app/python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('3.8.6 | packaged by conda-forge | (default, Dec 26 2020, 04:50:20) \\n[Clang 11.0.0 ]',\n",
       " '/Users/dblyon/anaconda3/envs/agotool/bin/python')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.version, sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "env_file missing\n",
      "##################################################\n"
     ]
    }
   ],
   "source": [
    "import query, variables, userinput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "UniProt_IDs_human_list = sorted(query.get_proteins_of_taxid(9606, read_from_flat_files=True))\n",
    "ENSP_human_list = sorted(query.get_proteins_of_human())\n",
    "###\n",
    "from itertools import islice\n",
    "\n",
    "def get_random_human_ENSP(num_ENSPs=20, joined_for_web=False, contiguous=False, UniProt_ID=False, UniProt_IDs_human_list=UniProt_IDs_human_list, ENSP_human_list=ENSP_human_list):\n",
    "    if UniProt_ID:\n",
    "        IDs_2_sample = UniProt_IDs_human_list\n",
    "    else:\n",
    "        IDs_2_sample = ENSP_human_list\n",
    "    max_index = len(IDs_2_sample)\n",
    "    if not contiguous:\n",
    "        if not joined_for_web:\n",
    "            return random.sample(IDs_2_sample, num_ENSPs)\n",
    "        else:\n",
    "            return \"%0d\".join(random.sample(IDs_2_sample, num_ENSPs))\n",
    "    else:\n",
    "        start_pos = np.random.randint(0, max_index)\n",
    "        if start_pos + num_ENSPs > max_index:\n",
    "            start_pos = max_index - num_ENSPs\n",
    "        stop_pos = start_pos + num_ENSPs\n",
    "        if not joined_for_web:\n",
    "            return list(islice(IDs_2_sample, start_pos, stop_pos))\n",
    "        else:\n",
    "            return \"%0d\".join(list(islice(IDs_2_sample, start_pos, stop_pos)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################################################\n",
      "env_file missing\n",
      "##################################################\n",
      "################################################################################\n",
      "initializing PQO\n",
      "getting taxid_2_proteome_count\n",
      "getting taxid_2_proteins_dict\n",
      "getting NCBI_taxonomy and TaxidSpecies_2_TaxidProteome_dict\n",
      "getting lookup arrays\n",
      "getting cond arrays\n",
      "getting lineage dict\n",
      "getting blacklisted terms\n",
      "getting taxid_2_tuple_funcEnum_index_2_associations_counts\n",
      "getting preloaded objects per analysis\n",
      "finished with PQO init\n",
      "go go GO and fly like the wind\n",
      "################################################################################\n"
     ]
    }
   ],
   "source": [
    "import query, variables\n",
    "from importlib import reload\n",
    "reload(query)\n",
    "reload(variables)\n",
    "variables.DB_DOCKER = False\n",
    "variables.DOCKER = False\n",
    "# taxid_2_funcEnum_index_2_associations --> taxid_2_tuple_funcEnum_index_2_associations_counts\n",
    "low_memory = True\n",
    "### preload\n",
    "pqo = query.PersistentQueryObject_STRING(low_memory)\n",
    "static_preloaded_objects = pqo.get_static_preloaded_objects(low_memory)\n",
    "### needed for scipy comparison, but otherwise deprecated\n",
    "# ENSP_2_tuple_funcEnum_score_dict = query.get_proteinAN_2_tuple_funcEnum_score_dict(read_from_flat_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_arr, hierlevel_arr, entitytype_arr, functionalterm_arr, indices_arr, description_arr, category_arr, etype_2_minmax_funcEnum, function_enumeration_len, etype_cond_dict, etype_2_num_functions_dict, taxid_2_proteome_count, taxid_2_tuple_funcEnum_index_2_associations_counts, lineage_dict_enum, blacklisted_terms_bool_arr, cond_etypes_with_ontology, cond_etypes_rem_foreground_ids, kegg_taxid_2_acronym_dict, goslimtype_2_cond_dict = static_preloaded_objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%%cython -f --compile-args=-DCYTHON_TRACE=1\n",
    "\n",
    "import Cython\n",
    "######################################\n",
    "### profiling # Set compiler directives (cf. http://docs.cython.org/src/reference/compilation.html)\n",
    "import line_profiler\n",
    "directive_defaults = Cython.Compiler.Options.get_directive_defaults() ### from Cython.Compiler.Options import directive_defaults # deprecated\n",
    "directive_defaults['linetrace'] = True\n",
    "directive_defaults['binding'] = True\n",
    "######################################\n",
    "from functools import reduce\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cython cimport boundscheck, wraparound, cdivision, nonecheck\n",
    "cimport cython\n",
    "cimport numpy as np\n",
    "ctypedef np.uint8_t uint8\n",
    "from collections import defaultdict\n",
    "from fisher import pvalue\n",
    "from scipy import stats\n",
    "import variables, query\n",
    "import time\n",
    "import colnames as cn\n",
    "\n",
    "\n",
    "\n",
    "def run_enrichment_cy(ncbi, ui, preloaded_objects_per_analysis, static_preloaded_objects, low_memory=False, debug=False):\n",
    "    if not low_memory:\n",
    "        ENSP_2_functionEnumArray_dict, year_arr, hierlevel_arr, entitytype_arr, functionalterm_arr, indices_arr, description_arr, category_arr, etype_2_minmax_funcEnum, function_enumeration_len, etype_cond_dict, etype_2_num_functions_dict, taxid_2_proteome_count, taxid_2_tuple_funcEnum_index_2_associations_counts, lineage_dict_enum, blacklisted_terms_bool_arr, cond_etypes_with_ontology, cond_etypes_rem_foreground_ids, kegg_taxid_2_acronym_dict, goslimtype_2_cond_dict = static_preloaded_objects\n",
    "    else:  # missing: ENSP_2_functionEnumArray_dict\n",
    "        year_arr, hierlevel_arr, entitytype_arr, functionalterm_arr, indices_arr, description_arr, category_arr, etype_2_minmax_funcEnum, function_enumeration_len, etype_cond_dict, etype_2_num_functions_dict, taxid_2_proteome_count, taxid_2_tuple_funcEnum_index_2_associations_counts, lineage_dict_enum, blacklisted_terms_bool_arr, cond_etypes_with_ontology, cond_etypes_rem_foreground_ids, kegg_taxid_2_acronym_dict, goslimtype_2_cond_dict = static_preloaded_objects\n",
    "    foreground_ids_arr_of_string, background_ids_arr_of_string, funcEnum_count_foreground, funcEnum_count_background, p_values, p_values_corrected, cond_multitest, blacklisted_terms_bool_arr_temp, cond_terms_reduced_with_ontology, cond_filter, cond_PMIDs, effectSizes, over_under_int_arr, over_under_arr_of_string = preloaded_objects_per_analysis\n",
    "    em = ui.enrichment_method\n",
    "    foreground_n = ui.get_foreground_n()\n",
    "    args_dict = ui.args_dict\n",
    "    background_n = ui.get_background_n()\n",
    "    protein_ans_fg = ui.get_foreground_an_set()\n",
    "    taxid = args_dict[\"taxid\"]\n",
    "    filter_foreground_count_one = args_dict[\"filter_foreground_count_one\"]\n",
    "    p_value_cutoff = args_dict[\"p_value_cutoff\"]\n",
    "\n",
    "    if ui.enrichment_method in {\"abundance_correction\", \"compare_samples\"}: # , \"compare_groups\"\n",
    "        protein_ans_bg = ui.get_background_an_set()\n",
    "    if low_memory:\n",
    "        ENSP_2_functionEnumArray_dict = query.get_functionEnumArray_from_proteins(ui.get_all_individual_AN(), dict_2_array=True)\n",
    "    ### add protein groups to ENSP_2_functionEnumArray_dict\n",
    "    ENSP_2_functionEnumArray_dict = add_protein_groups_to_ENSP_2_functionEnumArray_dict(ENSP_2_functionEnumArray_dict, ui.get_all_unique_proteinGroups())\n",
    "\n",
    "    count_all_terms(ENSP_2_functionEnumArray_dict, protein_ans_fg, funcEnum_count_foreground)\n",
    "\n",
    "    ### count background\n",
    "    if em == \"genome\":\n",
    "        funcEnum_index_2_associations = taxid_2_tuple_funcEnum_index_2_associations_counts[taxid]\n",
    "        funcEnum_index_positions_arr, counts_arr = funcEnum_index_2_associations\n",
    "        create_funcEnum_count_background_v3(funcEnum_count_background, funcEnum_index_positions_arr, counts_arr)\n",
    "    elif em == \"abundance_correction\":\n",
    "        funcEnum_count_background = count_all_term_abundance_corrected(ui, ENSP_2_functionEnumArray_dict, funcEnum_count_background)\n",
    "        background_n = foreground_n\n",
    "    elif em == \"compare_samples\":\n",
    "        count_all_terms(ENSP_2_functionEnumArray_dict, protein_ans_bg, funcEnum_count_background)\n",
    "    else:\n",
    "        args_dict[\"ERROR enrichment_method\"] = \"The 'enrichment_method' you've provided: '{}' doesn't exist / isn't implemented.\".format(args_dict[\"enrichment_method\"])\n",
    "        return args_dict\n",
    "\n",
    "    ## limit to given entity types\n",
    "    cond_limit_2_entity_type = limit_to_entity_types(args_dict[\"limit_2_entity_type\"], function_enumeration_len, etype_cond_dict, funcEnum_count_foreground)\n",
    "    limit_to_go_subset(etype_cond_dict, args_dict[\"go_slim_subset\"], goslimtype_2_cond_dict, funcEnum_count_foreground)\n",
    "    o_or_u_or_both_encoding = args_dict[\"o_or_u_or_both_encoding\"]\n",
    "\n",
    "    ### calculate Fisher p-values and get bool array for multiple testing\n",
    "\n",
    "    calc_pvalues(funcEnum_count_foreground, funcEnum_count_background, foreground_n, background_n, p_values, cond_multitest, effectSizes, over_under_int_arr, o_or_u_or_both_encoding)\n",
    "\n",
    "    ### \"over/under\"\n",
    "    if o_or_u_or_both_encoding == 1: # overrepresented\n",
    "        over_under_arr_of_string[over_under_int_arr == 1] = \"o\"\n",
    "    elif o_or_u_or_both_encoding == 0: # both\n",
    "        over_under_arr_of_string[over_under_int_arr == 1] = \"o\"\n",
    "        over_under_arr_of_string[over_under_int_arr == 2] = \"u\"\n",
    "    elif o_or_u_or_both_encoding == 2: # underrepresented\n",
    "        over_under_arr_of_string[over_under_int_arr == 2] = \"u\"\n",
    "    else: # check already done above\n",
    "        return args_dict\n",
    "    ### multiple testing per entity type, save results preformed p_values_corrected\n",
    "    if args_dict[\"multiple_testing_per_etype\"]:\n",
    "        for etype_name, cond_etype in etype_cond_dict.items():\n",
    "            if args_dict[\"multiple_testing_stringency\"] == \"A\":\n",
    "                num_total_tests = p_values[cond_etype & cond_multitest].shape[0] # sum(cond_etype & cond_multitest) is prohibitively slow!\n",
    "            else:\n",
    "                num_total_tests = etype_2_num_functions_dict[etype_name]\n",
    "            multiple_testing_per_entity_type(cond_etype, cond_multitest, p_values, p_values_corrected, indices_arr, num_total_tests)\n",
    "    else:\n",
    "        cond_all = np.ones(function_enumeration_len, dtype=bool)\n",
    "        if args_dict[\"multiple_testing_stringency\"] == \"A\":\n",
    "            num_total_tests = sum(cond_multitest)\n",
    "        else:\n",
    "            num_total_tests = cond_all.shape[0]\n",
    "        multiple_testing_per_entity_type(cond_all, cond_multitest, p_values, p_values_corrected, indices_arr, num_total_tests)\n",
    "\n",
    "\n",
    "    ### Filter stuff\n",
    "    foreground_ids_arr_of_string, funcEnum_indices_for_IDs, cond_etypes_with_ontology_filtered, cond_etypes_rem_foreground_ids_filtered, cond_filter = filter_stuff(args_dict, protein_ans_fg, p_values_corrected, foreground_ids_arr_of_string, funcEnum_count_foreground, year_arr, p_values, indices_arr, ENSP_2_functionEnumArray_dict, cond_filter, etype_cond_dict, cond_PMIDs, cond_etypes_with_ontology, cond_etypes_rem_foreground_ids, over_under_int_arr)\n",
    "    if debug:\n",
    "        return foreground_ids_arr_of_string\n",
    "    if em in {\"compare_samples\"}:\n",
    "        background_ids_arr_of_string = map_funcEnum_2_ENSPs(protein_ans_bg, ENSP_2_functionEnumArray_dict, funcEnum_indices_for_IDs, background_ids_arr_of_string)\n",
    "\n",
    "    ### filter etypes with ontologies --> cond_terms_reduced_with_ontology\n",
    "    df_with_ontology = pd.DataFrame({\"term_enum\": indices_arr[cond_etypes_with_ontology_filtered].view(), \"foreground_ids\": foreground_ids_arr_of_string[cond_etypes_with_ontology_filtered].view(), \"hierarchical_level\": hierlevel_arr[cond_etypes_with_ontology_filtered].view(), \"p_value\": p_values[cond_etypes_with_ontology_filtered].view(), \"foreground_count\": funcEnum_count_foreground[cond_etypes_with_ontology_filtered].view(), \"etype\": entitytype_arr[cond_etypes_with_ontology_filtered].view()})\n",
    "    if args_dict[\"filter_parents\"]: # only for etypes with ontology, but since foreground IDs needed get them for all\n",
    "        filter_parents_if_same_foreground(blacklisted_terms_bool_arr_temp, cond_terms_reduced_with_ontology, lineage_dict_enum, df_with_ontology) # modifies cond_terms_reduced_with_ontology inplace\n",
    "    else: # since no filtering done use all etypes with ontology\n",
    "        cond_terms_reduced_with_ontology = cond_filter & cond_etypes_with_ontology\n",
    "    ### concatenate filtered results\n",
    "    cond_2_return = cond_PMIDs | cond_terms_reduced_with_ontology | cond_etypes_rem_foreground_ids_filtered\n",
    "\n",
    "    df_2_return = pd.DataFrame({cn.term: functionalterm_arr[cond_2_return].view(),\n",
    "                            cn.hierarchical_level: hierlevel_arr[cond_2_return].view(),\n",
    "                            cn.p_value: p_values[cond_2_return].view(),\n",
    "                            cn.FDR: p_values_corrected[cond_2_return].view(),\n",
    "                            cn.category: category_arr[cond_2_return].view(),\n",
    "                            cn.etype: entitytype_arr[cond_2_return].view(),\n",
    "                            cn.description: description_arr[cond_2_return].view(),\n",
    "                            cn.year: year_arr[cond_2_return].view(),\n",
    "                            cn.FG_IDs: foreground_ids_arr_of_string[cond_2_return].view(),\n",
    "                            cn.FG_count: funcEnum_count_foreground[cond_2_return].view(),\n",
    "                            cn.BG_count: funcEnum_count_background[cond_2_return].view(),\n",
    "                            cn.effect_size: effectSizes[cond_2_return].view(),\n",
    "                            cn.over_under: over_under_arr_of_string[cond_2_return].view(),\n",
    "                            cn.funcEnum: indices_arr[cond_2_return].view()})\n",
    "\n",
    "    # cols_2_return_sort_order = cn.cols_2_return_run_enrichment_cy[:]\n",
    "    cols_2_return_sort_order = list(cn.cols_2_return_run_enrichment_cy)\n",
    "    if em in {\"compare_samples\"}:\n",
    "        df_2_return[cn.BG_IDs] = background_ids_arr_of_string[cond_2_return].view()\n",
    "    else:\n",
    "        cols_2_return_sort_order.remove(cn.BG_IDs)\n",
    "    df_2_return[\"s_value\"] = get_s_value(df_2_return)\n",
    "    # df_2_return[\"s_value_abs\"] = df_2_return[\"s_value\"].apply(lambda x: abs(x))\n",
    "    df_2_return[\"s_value_abs\"] = np.abs(df_2_return[\"s_value\"])\n",
    "    df_2_return = df_2_return.sort_values([cn.etype, \"s_value_abs\", cn.hierarchical_level, cn.year], ascending=[False, False, False, False]).reset_index(drop=True)\n",
    "    df_2_return[cn.rank] = df_2_return.groupby(cn.etype)[\"s_value_abs\"].rank(ascending=False, method=\"first\").fillna(value=df_2_return.shape[0]).astype(int)\n",
    "    if debug:\n",
    "            return protein_ans_bg, ENSP_2_functionEnumArray_dict, funcEnum_indices_for_IDs, background_ids_arr_of_string, df_2_return\n",
    "    df_2_return = ui.translate_primary_back_to_secondary(df_2_return)\n",
    "    df_2_return[cn.FG_n] = foreground_n\n",
    "    df_2_return[cn.BG_n] = background_n\n",
    "\n",
    "    ### calc ratio in foreground, count foreground / len(protein_ans)\n",
    "    df_2_return[cn.ratio_in_FG] = df_2_return[cn.FG_count] / df_2_return[cn.FG_n]\n",
    "    df_2_return[cn.ratio_in_BG] = df_2_return[cn.BG_count] / df_2_return[cn.BG_n]\n",
    "    if args_dict[\"STRING_beta\"]:\n",
    "        return df_2_return.rename(columns=cn.colnames_2_rename_dict_STRING_beta)[list(cn.cols_sort_order_STRING_beta)]\n",
    "    elif args_dict[\"STRING_API\"]:\n",
    "        df_2_return[\"ncbiTaxonId\"] = taxid\n",
    "        df_2_return[\"preferredNames\"] = \"\"\n",
    "        return df_2_return.rename(columns=cn.colnames_2_rename_dict_STRING_API)[list(cn.cols_sort_order_STRING_API_genome_or_compare_samples)]\n",
    "    return df_2_return[cols_2_return_sort_order]\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef calc_pvalues(unsigned int[::1] funcEnum_count_foreground,\n",
    "                  unsigned int[::1] funcEnum_count_background,\n",
    "                  unsigned int foreground_n,\n",
    "                  unsigned int background_n,\n",
    "                  double[::1] p_values,\n",
    "                  cond_multitest,\n",
    "                  double[::1] effectSizes,\n",
    "                  unsigned int[::1] over_under_int_arr,\n",
    "                  unsigned int o_or_u_or_both_encoding):\n",
    "    cdef:\n",
    "        int index_, foreground_count, background_count, a, b, c, d\n",
    "        int len_functions = funcEnum_count_foreground.shape[0]\n",
    "        dict fisher_dict = {}\n",
    "        double p_val_uncorrected\n",
    "        double odds_ratio\n",
    "\n",
    "    for index_ in range(len_functions):\n",
    "        foreground_count = funcEnum_count_foreground[index_]\n",
    "        if foreground_count > 0:\n",
    "            cond_multitest[index_] = True\n",
    "            over_under_int_arr[index_] = 3 # meaningless encoding in order not to filter out things later if p_value_cutoff == 1\n",
    "            if foreground_count == 1: # leave p-value set to 1, BUT DO multiple testing\n",
    "                continue\n",
    "            background_count = funcEnum_count_background[index_]\n",
    "            a = foreground_count # number of proteins associated with given GO-term\n",
    "            b = foreground_n - foreground_count # number of proteins not associated with GO-term\n",
    "            c = background_count\n",
    "            d = background_n - background_count\n",
    "            p_val_uncorrected = fisher_dict.get((a, b, c, d), -1)\n",
    "            if p_val_uncorrected == -1:\n",
    "                if o_or_u_or_both_encoding == 1: # overrepresented\n",
    "                    p_val_uncorrected = pvalue(a, b, c, d).right_tail\n",
    "                    over_under_int_arr[index_] = 1\n",
    "                elif o_or_u_or_both_encoding == 0: # both\n",
    "                    p_val_uncorrected = pvalue(a, b, c, d).two_tail\n",
    "                    try:\n",
    "                        is_greater = (a / (a + b)) > (c / (c + d))\n",
    "                        if is_greater:\n",
    "                            is_greater = 1\n",
    "                        else:\n",
    "                            is_greater = 2\n",
    "                    except ZeroDivisionError:\n",
    "                        is_greater = 0 # np.nan\n",
    "                    over_under_int_arr[index_] = is_greater\n",
    "                elif o_or_u_or_both_encoding == 2: # underrepresented\n",
    "                    p_val_uncorrected = pvalue(a, b, c, d).left_tail\n",
    "                    over_under_int_arr[index_] = 2\n",
    "                else:\n",
    "                    p_val_uncorrected = 1\n",
    "                    over_under_int_arr[index_] = 3\n",
    "                fisher_dict[(a, b, c, d)] = p_val_uncorrected\n",
    "            else: # write over_under but don't calc pvalue\n",
    "                if o_or_u_or_both_encoding == 1: # overrepresented\n",
    "                    over_under_int_arr[index_] = 1\n",
    "                elif o_or_u_or_both_encoding == 0: # both\n",
    "                    try:\n",
    "                        is_greater = (a / (a + b)) > (c / (c + d))\n",
    "                    except ZeroDivisionError:\n",
    "                        is_greater = np.nan # ??? shouldn't this be 0 instead of np.nan ???\n",
    "                    over_under_int_arr[index_] = is_greater\n",
    "                elif o_or_u_or_both_encoding == 2: # underrepresented\n",
    "                    over_under_int_arr[index_] = 2\n",
    "                else:\n",
    "                    over_under_int_arr[index_] = 3 # which caser is this supposed to be?\n",
    "            p_values[index_] = p_val_uncorrected\n",
    "            try:\n",
    "                # https://stats.stackexchange.com/questions/22508/effect-size-for-fishers-exact-test\n",
    "                # odds_ratio = (a * d) / (b * c) # true odds ratio\n",
    "                # odds_ratio = (d / (c + d)) - (a / (a + b)) # difference in proportions\n",
    "                odds_ratio = (a / (a + b)) - (c / (c + d)) # difference in proportions DBL\n",
    "                # odds_ratio = (a / (a + b)) / (c / (c + d)) # from old agotool, ratio of percent in fg to percent in bg\n",
    "            except ZeroDivisionError:\n",
    "                odds_ratio = np.nan\n",
    "            effectSizes[index_] = odds_ratio\n",
    "    return 0\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef int create_funcEnum_count_background_v3(unsigned int[::1] funcEnum_count_background,\n",
    "                                         const unsigned int[::1] funcEnum_index_arr, # uint32\n",
    "                                         const unsigned int[::1] count_arr): # uint32\n",
    "    cdef:\n",
    "        int i, N = funcEnum_index_arr.shape[0]\n",
    "        unsigned int index_\n",
    "        unsigned short count\n",
    "\n",
    "    for i in range(N):\n",
    "        index_ = funcEnum_index_arr[i]\n",
    "        count = count_arr[i]\n",
    "        funcEnum_count_background[index_] = count\n",
    "    return 0\n",
    "\n",
    "def count_all_term_abundance_corrected(ui, ENSP_2_functionEnumArray_dict, funcEnum_count):\n",
    "    funcEnum_count_float = np.zeros(funcEnum_count.shape[0], dtype=np.dtype(\"float64\"))\n",
    "    for proteinGroup_list, correction_factor in ui.iter_bins():\n",
    "        for proteinGroup in proteinGroup_list:\n",
    "            try:\n",
    "                funcEnum_associations = ENSP_2_functionEnumArray_dict[proteinGroup]\n",
    "            except KeyError: # no functional annotation for proteins\n",
    "                continue\n",
    "            count_terms_cy_abundance_corrected(correction_factor, funcEnum_associations, funcEnum_count_float)\n",
    "    funcEnum_count = np.around(funcEnum_count_float).astype(dtype=np.dtype(\"uint32\"))\n",
    "    return funcEnum_count\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef int count_terms_cy_abundance_corrected(double correction_factor,\n",
    "                                        unsigned int[::1] funcEnum_associations,\n",
    "                                        double[::1] funcEnum_count_float):\n",
    "    cdef int N, i, k\n",
    "    N = funcEnum_associations.shape[0]\n",
    "    for i in range(N):\n",
    "        k = funcEnum_associations[i]\n",
    "        funcEnum_count_float[k] += correction_factor\n",
    "    return 0\n",
    "\n",
    "def count_all_terms(ENSP_2_functionEnumArray_dict, protein_ans, funcEnum_count):\n",
    "    for ENSP in (ENSP for ENSP in protein_ans if ENSP in ENSP_2_functionEnumArray_dict):\n",
    "        funcEnumAssociations = ENSP_2_functionEnumArray_dict[ENSP]\n",
    "        count_terms_cy(funcEnumAssociations, funcEnum_count)\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef int count_terms_cy(unsigned int[::1] funcEnum_associations,\n",
    "                    unsigned int[::1] funcEnum_count):\n",
    "    \"\"\"\n",
    "    without returning 'funcEnum_count' the function does inplace change of 'funcEnum_count'\n",
    "    :param funcEnum_associations: np.array (of variable length, with functional associations \n",
    "    as enumerations (instead of strings), \n",
    "    uint32, i.e. which functional associations are given for provided user input proteins)\n",
    "    :param funcEnum_count: np.array (shape of array from 0 to max enumeration of functional-terms, \n",
    "    uint32, each position codes for \n",
    "    a specific functional term, the value is a count for the given user input)\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    cdef int N, i, k\n",
    "    N = funcEnum_associations.shape[0]\n",
    "    for i in range(N):\n",
    "        k = funcEnum_associations[i]\n",
    "        funcEnum_count[k] += 1\n",
    "    return 0\n",
    "\n",
    "def collect_scores_per_term_characterize_foreground(protein_AN_list, ENSP_2_tuple_funcEnum_score_dict, funcEnums_2_include_set, score_cutoff=3):\n",
    "    funcEnum_2_scores_dict = defaultdict(lambda: [])\n",
    "    for protein_AN in protein_AN_list:\n",
    "        funcEnum_already_counted = set()\n",
    "        try:\n",
    "            funcEnum_score = ENSP_2_tuple_funcEnum_score_dict[protein_AN]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        funcEnum_arr, score_arr = funcEnum_score\n",
    "        len_funcEnum_arr = len(funcEnum_arr)\n",
    "        for index_ in range(len_funcEnum_arr):\n",
    "            funcEnum = funcEnum_arr[index_]\n",
    "            if funcEnum in funcEnums_2_include_set:\n",
    "                score = score_arr[index_]\n",
    "                if score >= score_cutoff:\n",
    "                    if funcEnum not in funcEnum_already_counted:\n",
    "                        # in order to count a function only once per protein\n",
    "                        funcEnum_2_scores_dict[funcEnum].append(score)\n",
    "                        funcEnum_already_counted.update(set([funcEnum]))\n",
    "    return funcEnum_2_scores_dict\n",
    "\n",
    "def collect_scores_per_term(protein_AN_list, ENSP_2_tuple_funcEnum_score_dict, list_2_array=False):\n",
    "    \"\"\"\n",
    "    ENSP_2_tuple_funcEnum_score_dict['3702.AT1G01010.1']\n",
    "    (array([ 211,  252,  253], dtype=uint32),\n",
    "     array([4200000, 4166357, 4195121], dtype=uint32))\n",
    "    funcEnum_2_scores_dict: key: functionEnumeration, val: list of scores\n",
    "    \"\"\"\n",
    "    funcEnum_2_scores_dict = defaultdict(lambda: [])\n",
    "    for protein_AN in protein_AN_list:\n",
    "        try:\n",
    "            funcEnum_score = ENSP_2_tuple_funcEnum_score_dict[protein_AN]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        funcEnum_arr, score_arr = funcEnum_score\n",
    "        len_funcEnum_arr = len(funcEnum_arr)\n",
    "        for index_ in range(len_funcEnum_arr):\n",
    "            score = score_arr[index_]\n",
    "            funcEnum_2_scores_dict[funcEnum_arr[index_]].append(score)\n",
    "    if list_2_array:\n",
    "        return {funcEnum: np.asarray(scores, dtype=np.dtype(variables.dtype_TM_score)) for funcEnum, scores in funcEnum_2_scores_dict.items()} # float64 --> uint32\n",
    "    # since concatenating np.arrays later on (for filling with zeros) produces 64 bit array anyway\n",
    "    else:\n",
    "        return funcEnum_2_scores_dict\n",
    "\n",
    "def collect_scores_per_term_limit_2_inclusionTerms(protein_AN_list, ENSP_2_tuple_funcEnum_score_dict, funcEnums_2_include_set, list_2_array=False):\n",
    "    \"\"\"\n",
    "    for a given protein: a functional term should only have a single score (not multiple as previously)\n",
    "    ENSP_2_tuple_funcEnum_score_dict['3702.AT1G01010.1']\n",
    "    (array([ 211,  252,  253], dtype=uint32),\n",
    "     array([420000, 4166357, 4195121], dtype=uint32))\n",
    "    funcEnum_2_scores_dict: key: functionEnumeration, val: list of Integer scores ( )\n",
    "    \"\"\"\n",
    "    len_protein_AN_list = len(protein_AN_list)\n",
    "    funcEnum_2_scores_dict = defaultdict(lambda: [0]*len_protein_AN_list)\n",
    "    for index_protein, protein_AN in enumerate(protein_AN_list):\n",
    "        try:\n",
    "            funcEnum_score = ENSP_2_tuple_funcEnum_score_dict[protein_AN]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        funcEnum_arr, score_arr = funcEnum_score\n",
    "        len_funcEnum_arr = len(funcEnum_arr)\n",
    "        for index_ in range(len_funcEnum_arr):\n",
    "            funcEnum = funcEnum_arr[index_]\n",
    "            if funcEnum in funcEnums_2_include_set:\n",
    "                score = score_arr[index_]\n",
    "                funcEnum_2_scores_dict[funcEnum][index_protein] = score # funcEnum_2_scores_dict[funcEnum].append(score)\n",
    "    if list_2_array:\n",
    "        return {funcEnum: np.asarray(scores, dtype=np.dtype(variables.dtype_TM_score)) for funcEnum, scores in funcEnum_2_scores_dict.items()}\n",
    "    # since concatenating np.arrays later on (for filling with zeros) produces 64 bit array anyway\n",
    "    else:\n",
    "        return funcEnum_2_scores_dict\n",
    "\n",
    "def collect_scores_per_term_abundance_corrected(ui, ENSP_2_tuple_funcEnum_score_dict, funcEnums_2_include_set, list_2_array=False):\n",
    "    funcEnum_2_scores_dict = defaultdict(lambda: [])\n",
    "    for proteinGroup_list, correction_factor in ui.iter_bins():\n",
    "        for proteinGroup in proteinGroup_list:\n",
    "            try:\n",
    "                funcEnum_score = ENSP_2_tuple_funcEnum_score_dict[proteinGroup]\n",
    "            except KeyError:\n",
    "                continue\n",
    "            funcEnum_arr, score_arr = funcEnum_score\n",
    "            len_funcEnum_arr = len(funcEnum_arr)\n",
    "            for index_ in range(len_funcEnum_arr):\n",
    "                funcEnum = funcEnum_arr[index_]\n",
    "                if funcEnum in funcEnums_2_include_set:\n",
    "                    score = score_arr[index_]\n",
    "                    funcEnum_2_scores_dict[funcEnum].append(score*correction_factor)\n",
    "    if list_2_array:\n",
    "        return {funcEnum: np.asarray(scores, dtype=np.dtype(variables.dtype_TM_score)) for funcEnum, scores in funcEnum_2_scores_dict.items()}\n",
    "        # since concatenating np.arrays later on (for filling with zeros) produces 64 bit array anyway\n",
    "    else:\n",
    "        return funcEnum_2_scores_dict\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "@cdivision(True)\n",
    "cdef BenjaminiHochberg_cy(double[::1] p_values,\n",
    "                         unsigned int num_total_tests,\n",
    "                         double[::1] p_values_corrected,\n",
    "                         unsigned int[::1] indices_2_BH):\n",
    "    \"\"\"\n",
    "    #!!! cpdef instead of cdef for scores debugging/profiling\n",
    "    ein index array mit absoluten positionen, pvals absolut und pvalscorr absolut\n",
    "    p_values_2_BH, p_values_2_BH.shape[0], p_values_corrected_2_BH, indices_of_p_values_2_BH)\n",
    "    :param p_values: unsorted array of float\n",
    "    :param num_total_tests: Integer (number of all possible tests within etype/category, regardless of input)\n",
    "    :param p_values_corrected: array of float (1.0 by default), shape is full function_enumeration_len NOT p_values    \n",
    "    :param indices_2_BH: indices of superset, shape of array reduced to p_values_2_BH\n",
    "    iterate over p_values in p_values_2_BH_sort_order\n",
    "    set p_value_corrected at positions from indices_2_BH[p_values_2_BH_sort_order]\n",
    "    \"\"\"\n",
    "    cdef:\n",
    "        double prev_bh_value = 0.0\n",
    "        double p_value, bh_value\n",
    "        unsigned int index_2_BH, i\n",
    "        unsigned int enum_counter = 1\n",
    "        unsigned int N = indices_2_BH.shape[0]\n",
    "\n",
    "    for i in range(N):\n",
    "        index_2_BH = indices_2_BH[i]\n",
    "        p_value = p_values[index_2_BH]\n",
    "        bh_value = p_value * num_total_tests / enum_counter\n",
    "        # Sometimes this correction can give values greater than 1,\n",
    "        # so we set those values at 1\n",
    "        bh_value = min(bh_value, 1)\n",
    "        # To preserve monotonicity in the values, we take the\n",
    "        # maximum of the previous value or this one, so that we\n",
    "        # don't yield a value less than the previous.\n",
    "        bh_value = max(bh_value, prev_bh_value)\n",
    "        prev_bh_value = bh_value\n",
    "        p_values_corrected[index_2_BH] = bh_value\n",
    "        enum_counter += 1\n",
    "\n",
    "def map_funcEnum_2_ENSPs(protein_ans_list, ENSP_2_functionEnumArray_dict, funcEnum_indices, foreground_ids_arr_of_string):\n",
    "    \"\"\"\n",
    "    previously named get_foreground_IDs_arr now map_funcEnum_2_ENSPs\n",
    "    for given protein_ans produce concatenate strings of ENSP associations\n",
    "    :param protein_ans_list: List of String (or array), user provided ENSPs\n",
    "    :param ENSP_2_functionEnumArray_dict: key: String, val: array of uint32, all ENSP to function enum associations\n",
    "    :param funcEnum_indices: array of uint32, relevant func enums after filtering\n",
    "    :param foreground_ids_arr_of_string: list of empty string, len of function_enumeration_len, list instead of array since len of longest string unknown and would take lots of memory\n",
    "    :return: List of String of len function_enumeration_len with comma sep ENSPs at index positions coding for func enum\n",
    "    \"\"\"\n",
    "    funcEnum_2_ENSPs_dict = {index_: [] for index_ in funcEnum_indices}\n",
    "    for ENSP in protein_ans_list:\n",
    "        try:\n",
    "            functionEnumArray = ENSP_2_functionEnumArray_dict[ENSP]\n",
    "        except KeyError: # happens since some ENSPs are without functional associations (or if single association in genome it is filtered out)\n",
    "            continue\n",
    "        for funcEnum in functionEnumArray:\n",
    "            if funcEnum in funcEnum_2_ENSPs_dict:\n",
    "                funcEnum_2_ENSPs_dict[funcEnum].append(ENSP)\n",
    "\n",
    "    for funcEnum, ENSPs in funcEnum_2_ENSPs_dict.items():\n",
    "        foreground_ids_arr_of_string[funcEnum] = \";\".join(sorted(set(ENSPs))) # needs to be sorted otherwise grouping incorrect later on\n",
    "    return foreground_ids_arr_of_string\n",
    "\n",
    "def get_preloaded_objects_for_single_analysis(blacklisted_terms_bool_arr, function_enumeration_len=6834675):\n",
    "    \"\"\"\n",
    "    funcEnum_count_foreground, funcEnum_count_background, p_values, p_values_corrected, cond_multitest, blacklisted_terms_bool_arr_temp, cond_terms_reduced_with_ontology, foreground_ids_arr_of_string, cond_filter, cond_PMIDs\n",
    "    \"\"\"\n",
    "    funcEnum_count_foreground = np.zeros(shape=function_enumeration_len, dtype=np.dtype(\"uint32\"))\n",
    "    foreground_ids_arr_of_string = np.empty(shape=(function_enumeration_len,), dtype=object)\n",
    "    blacklisted_terms_bool_arr_temp = blacklisted_terms_bool_arr.copy()\n",
    "    # was uint32, but uint16 is sufficient for STRING v11, not using it for the foreground due to potential redundancy\n",
    "    # or for \"compare_samples\" for the same reason --> keep the same\n",
    "    funcEnum_count_background = np.zeros(shape=function_enumeration_len, dtype=np.dtype(\"uint32\"))\n",
    "    p_values = np.ones(shape=function_enumeration_len, dtype=np.dtype(\"float64\"))\n",
    "    p_values_corrected = np.ones(shape=function_enumeration_len, dtype=np.dtype(\"float64\"))\n",
    "    cond_multitest = np.zeros(function_enumeration_len, dtype=bool)\n",
    "    cond_filter = np.ones(function_enumeration_len, dtype=bool)\n",
    "    cond_PMIDs = np.zeros(function_enumeration_len, dtype=bool)\n",
    "    cond_terms_reduced_with_ontology = np.zeros(function_enumeration_len, dtype=bool)\n",
    "    background_ids_arr_of_string = np.empty(shape=(function_enumeration_len,), dtype=object)\n",
    "    effectSizes = np.empty(function_enumeration_len, dtype=np.dtype(\"float64\"))\n",
    "    effectSizes.fill(np.nan)\n",
    "    over_under_int_arr = np.zeros(function_enumeration_len, dtype=np.dtype(\"uint32\")) # encoding of 1: \"overrepresented\", 2: \"underrepresented\", 0: \"NaN\"\n",
    "    over_under_arr_of_string = np.empty(function_enumeration_len, np.dtype(\"U1\"))\n",
    "    return foreground_ids_arr_of_string, background_ids_arr_of_string, funcEnum_count_foreground, funcEnum_count_background, p_values, p_values_corrected, cond_multitest, blacklisted_terms_bool_arr_temp, cond_terms_reduced_with_ontology, cond_filter, cond_PMIDs, effectSizes, over_under_int_arr, over_under_arr_of_string\n",
    "\n",
    "@boundscheck(False)\n",
    "@wraparound(False)\n",
    "cdef filter_parents_if_same_foreground(uint8[::1] blacklisted_terms_bool_arr_temp,\n",
    "                                       cond_terms_reduced_with_ontology,\n",
    "                                       dict lineage_dict_enum,\n",
    "                                       df):\n",
    "    \"\"\"    \n",
    "    potential speed up using C++ types for sets, BUT data is copied so profile \n",
    "\n",
    "    # distutils: language = c++    \n",
    "    from libcpp.vector cimport vector\n",
    "    from libcpp.set cimport set \n",
    "    \"\"\"\n",
    "    cdef:\n",
    "        unsigned int term_enum, lineage_term\n",
    "        # unsigned int lineage\n",
    "\n",
    "    for group_terms in df.sort_values([\"foreground_ids\", \"p_value\", \"hierarchical_level\"], ascending=[True, True, False]).groupby(\"foreground_ids\", sort=False).apply(lambda group: group[\"term_enum\"].values):\n",
    "        group_terms_set = set(group_terms)\n",
    "        for term_enum in group_terms:\n",
    "            if blacklisted_terms_bool_arr_temp[term_enum] == 0: # False\n",
    "                cond_terms_reduced_with_ontology[term_enum] = True\n",
    "                try:\n",
    "                    lineage = lineage_dict_enum[term_enum] & group_terms_set # bitwise intersection\n",
    "                except KeyError: # not in hierarchy (even though it should be, but some Reactome terms are inconsistent)\n",
    "                    blacklisted_terms_bool_arr_temp[term_enum] = 1 # True\n",
    "                    continue\n",
    "                for lineage_term in lineage:\n",
    "                    blacklisted_terms_bool_arr_temp[lineage_term] = 1 # True\n",
    "\n",
    "def multiple_testing_per_entity_type(cond_etype, cond_multitest, p_values, p_values_corrected, indices_arr, num_total_tests):\n",
    "    # select indices for given entity type and if multiple testing needs to be applied\n",
    "    cond = cond_etype & cond_multitest\n",
    "    # select p_values for BenjaminiHochberg\n",
    "    p_values_2_BH = p_values[cond]\n",
    "    # previously: num_total_tests = p_values_2_BH.shape[0]\n",
    "    # select indices for BH\n",
    "    indices_2_BH = indices_arr[cond]\n",
    "    # sort p_values and remember indices sort order\n",
    "    p_values_2_BH_sort_order = np.argsort(p_values_2_BH) # index positions of a reduced set\n",
    "    indices_2_BH_of_superset = indices_2_BH[p_values_2_BH_sort_order]\n",
    "    BenjaminiHochberg_cy(p_values, num_total_tests, p_values_corrected, indices_2_BH_of_superset)\n",
    "\n",
    "def get_s_value(df, p_value_cutoff=0.05, KS_stat_cutoff=0.1, diff_proportions_cutoff=0.1):\n",
    "    \"\"\"\n",
    "    calculate 's-value' type statistic in order to rank based on a combination of p-value and effect size\n",
    "    for etypes -20, -25, and -26 (GOCC, BTO, and DOID) --> Common Language Effect Size\n",
    "    for other etypes difference in ratios\n",
    "    justification for cles_cutoff --> Kerby (https://doi.org/10.2466%2F11.IT.3.1) if the null is true the CLES is 50%\n",
    "    justification for diff_proportions_cutoff --> unsure how to justify from lit. need be smaller than cles_cutoff\n",
    "    --> changed from cles to KS_stat\n",
    "    \"\"\"\n",
    "    min_pval = df[cn.p_value][df[cn.p_value] > 0].min()\n",
    "    df[\"p_value_minlog\"] = df[cn.p_value].apply(log_take_min_if_zero, args=(min_pval, ))\n",
    "    df[cn.s_value] = 0.0\n",
    "    # cond_scores = df[cn.etype].isin([-20, -25, -26])\n",
    "    # p_value_cutoff = -1 * math.log10(p_value_cutoff) # test for values smaller than 0\n",
    "    df[cn.s_value] = df[\"p_value_minlog\"] * df[cn.effect_size]\n",
    "    # df = df.drop(columns=[\"p_value_minlog\"])\n",
    "    return df[cn.s_value]\n",
    "\n",
    "def log_take_min_if_zero(val, min_pval):\n",
    "    try:\n",
    "        return -1*math.log10(val)\n",
    "    except:\n",
    "        return -1*math.log10(min_pval)\n",
    "\n",
    "def limit_to_entity_types(limit_2_entity_type, function_enumeration_len, etype_cond_dict, funcEnum_count_foreground):\n",
    "    if limit_2_entity_type is not None:\n",
    "        cond_limit_2_entity_type = np.zeros(function_enumeration_len, dtype=bool)\n",
    "        for cond_name in [\"cond_\" + etype[1:] for etype in limit_2_entity_type.split(\";\")]:\n",
    "            try:\n",
    "                cond_limit_2_entity_type |= etype_cond_dict[cond_name] # add other etypes\n",
    "            except KeyError: # user provided etype can be mistyped of non-existent\n",
    "                pass\n",
    "        # set funcEnumAssociations to zero where cond_limit_2_entity_type is False\n",
    "        funcEnum_count_foreground[~cond_limit_2_entity_type] = 0\n",
    "        return cond_limit_2_entity_type # return bool arr of locations that should NOT be tested\n",
    "    else:\n",
    "        return np.ones(function_enumeration_len, dtype=bool)\n",
    "\n",
    "def limit_to_go_subset(etype_cond_dict, go_slim_subset, goslimtype_2_cond_dict, funcEnum_count_foreground):\n",
    "    if go_slim_subset is None:\n",
    "        return funcEnum_count_foreground\n",
    "    cond_GO_etypes = etype_cond_dict[\"cond_21\"] | etype_cond_dict[\"cond_22\"] | etype_cond_dict[\"cond_23\"]\n",
    "    cond = cond_GO_etypes != goslimtype_2_cond_dict[go_slim_subset] # select all GO terms that are not slim\n",
    "    # set these to count 0\n",
    "    funcEnum_count_foreground[cond] = 0\n",
    "    return funcEnum_count_foreground\n",
    "\n",
    "def add_funcEnums_2_dict(protein_ans_fg, ENSP_2_functionEnumArray_dict, ENSP_2_tuple_funcEnum_score_dict):\n",
    "    ### add Protein 2 functionEnum info for JensenLabScore data to get foregroundIDs in DF\n",
    "    for protein in protein_ans_fg:\n",
    "        try: # sort is probably not necessary # potential speedup removing the sorting\n",
    "            ENSP_2_functionEnumArray_dict[protein] = np.sort(np.concatenate((ENSP_2_tuple_funcEnum_score_dict[protein][0], ENSP_2_functionEnumArray_dict[protein])))\n",
    "        except KeyError:\n",
    "            pass # print(\"protein {} not in ENSP_2_tuple_funcEnum_score_dict\".format(protein)) # --> simply not annotated with anything from textmining\n",
    "\n",
    "def add_funcEnums_2_dict_CSC(protein_AN_set, ENSP_2_functionEnumArray_dict, ENSP_2_rowIndex_dict, CSR_ENSPencoding_2_FuncEnum):\n",
    "    \"\"\"\n",
    "    rowIndex = ENSP_2_rowIndex_dict[\"128UP_DROME\"]\n",
    "    CSR_ENSPencoding_2_FuncEnum[rowIndex].indices # --> FunEnums_array == ENSP_2_tuple_funcEnum_score_dict[\"128UP_DROME\"][0]\n",
    "    CSR_ENSPencoding_2_FuncEnum[rowIndex].data # --> Scores_array == ENSP_2_tuple_funcEnum_score_dict[ensp][1]\n",
    "    \"\"\"\n",
    "    for protein in protein_AN_set:\n",
    "        try:\n",
    "            rowIndex = ENSP_2_rowIndex_dict[protein]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        funcEnum_array = CSR_ENSPencoding_2_FuncEnum[rowIndex].indices\n",
    "        ENSP_2_functionEnumArray_dict[protein] = np.sort(np.concatenate((funcEnum_array, ENSP_2_functionEnumArray_dict[protein])))\n",
    "\n",
    "def replace_secondary_and_primary_IDs(ans_string, secondary_2_primary_dict, invert_dict=False):\n",
    "    if invert_dict:\n",
    "        dict_2_use = {v: k for k, v in secondary_2_primary_dict.items()}\n",
    "    else:\n",
    "        dict_2_use = secondary_2_primary_dict\n",
    "    ids_2_return = []\n",
    "    for id_ in ans_string.split(\";\"): # if proteinGroup\n",
    "        if id_ in dict_2_use:\n",
    "            ids_2_return.append(dict_2_use[id_])\n",
    "        else:\n",
    "            ids_2_return.append(id_)\n",
    "    return \";\".join(ids_2_return)\n",
    "\n",
    "def add_protein_groups_to_ENSP_2_functionEnumArray_dict(ENSP_2_functionEnumArray_dict, all_unique_proteinGroups):\n",
    "    \"\"\"\n",
    "    for all protein groups\n",
    "    \"\"\"\n",
    "    for proteinGroup in all_unique_proteinGroups:\n",
    "        if proteinGroup not in ENSP_2_functionEnumArray_dict:\n",
    "            functionEnumArray_list = []\n",
    "            for protein in proteinGroup.split(\";\"):\n",
    "                try:\n",
    "                    functionEnumArray_list.append(ENSP_2_functionEnumArray_dict[protein])\n",
    "                except KeyError: # no functional annotation for given protein\n",
    "                    pass\n",
    "            try:\n",
    "                ENSP_2_functionEnumArray_dict[proteinGroup] = reduce(np.union1d, functionEnumArray_list)\n",
    "            except TypeError: # empty list\n",
    "                #ENSP_2_functionEnumArray_dict[proteinGroup] = False #np.array(dtype=np.dtype(\"uint32\"))\n",
    "                pass\n",
    "    return ENSP_2_functionEnumArray_dict\n",
    "\n",
    "def filter_stuff(args_dict, protein_ans_fg, p_values_corrected, foreground_ids_arr_of_string, funcEnum_count_foreground, year_arr, p_values, indices_arr, ENSP_2_functionEnumArray_dict, cond_filter, etype_cond_dict, cond_PMIDs, cond_etypes_with_ontology, cond_etypes_rem_foreground_ids, over_under_int_arr):\n",
    "    FDR_cutoff, p_value_cutoff = args_dict[\"FDR_cutoff\"], args_dict[\"p_value_cutoff\"]\n",
    "    cond_filter = (p_values_corrected <= FDR_cutoff) & (p_values <= p_value_cutoff)\n",
    "    ### remove terms with only a single annotation\n",
    "    if args_dict[\"filter_foreground_count_one\"] is True:\n",
    "        cond_filter &= funcEnum_count_foreground > 1\n",
    "    else:  # remove terms without any annotation\n",
    "        cond_filter &= funcEnum_count_foreground > 0\n",
    "\n",
    "    ### overrepresented/underrepresented/both\n",
    "    o_or_u_or_both_encoding = args_dict[\"o_or_u_or_both_encoding\"]\n",
    "    if o_or_u_or_both_encoding == 1: # overrepresented\n",
    "        cond_o_or_u_or_both = over_under_int_arr == 1\n",
    "    elif o_or_u_or_both_encoding == 2: # underrepresented\n",
    "        cond_o_or_u_or_both = over_under_int_arr == 2\n",
    "    elif o_or_u_or_both_encoding == 0: # both\n",
    "        cond_o_or_u_or_both = over_under_int_arr > 0\n",
    "    else:\n",
    "        pass # should not happen\n",
    "    cond_filter &= cond_o_or_u_or_both\n",
    "    filter_PMID_top_n = args_dict[\"filter_PMID_top_n\"]\n",
    "    if filter_PMID_top_n is not None:\n",
    "        cond_PMID_2_filter = cond_filter & etype_cond_dict[\"cond_56\"]  # -56\n",
    "        df_PMID = pd.DataFrame({\"foreground_count\": funcEnum_count_foreground[cond_PMID_2_filter].view(), \"year\": year_arr[cond_PMID_2_filter].view(), \"p_value\": p_values[cond_PMID_2_filter].view(), \"FDR\": p_values_corrected[cond_PMID_2_filter].view(), \"indices_arr\": indices_arr[cond_PMID_2_filter].view()})\n",
    "        indices_PMID = df_PMID.sort_values([\"FDR\", \"p_value\", \"year\", \"foreground_count\"], ascending=[True, True, False, False])[\"indices_arr\"].values[:filter_PMID_top_n]\n",
    "        for index_ in indices_PMID:\n",
    "            cond_PMIDs[index_] = True\n",
    "    else:  # since no filtering use all PMIDs\n",
    "        cond_PMIDs = cond_filter & etype_cond_dict[\"cond_56\"]\n",
    "    cond_etypes_with_ontology_filtered = cond_etypes_with_ontology & cond_filter  # {-21, -22, -23, -51, -57}\n",
    "    # entity_types_with_ontology = {-20, -21, -22, -23, -25, -26, -51, -57} # Interpro has ontology, but omitted here to turn off filter_parents functionality\n",
    "    cond_etypes_rem_foreground_ids_filtered = cond_etypes_rem_foreground_ids & cond_filter  # remaining etypes -52, -53, -54, -55\n",
    "    cond_IDs_2_query = (cond_PMIDs | cond_etypes_with_ontology_filtered | cond_etypes_rem_foreground_ids_filtered)\n",
    "    ### get foreground IDs of relevant subset --> array for entire data set\n",
    "    ## exclude TextMining KS functionEnumerations since these are probably not very informative and we need performance --> don't exclude\n",
    "#     if not KS_etypes_FG_IDs:\n",
    "#         cond_IDs_2_query = cond_IDs_2_query & ~cond_KS_etypes # commented on purpose since STRING needs these\n",
    "    funcEnum_indices_for_IDs = indices_arr[cond_IDs_2_query]\n",
    "    foreground_ids_arr_of_string = map_funcEnum_2_ENSPs(protein_ans_fg, ENSP_2_functionEnumArray_dict, funcEnum_indices_for_IDs, foreground_ids_arr_of_string)\n",
    "#     if not KS_etypes_FG_IDs:\n",
    "#         foreground_ids_arr_of_string[cond_KS_etypes] = \"\" # commented out for STRING\n",
    "    return foreground_ids_arr_of_string, funcEnum_indices_for_IDs, cond_etypes_with_ontology_filtered, cond_etypes_rem_foreground_ids_filtered, cond_filter\n",
    "\n",
    "def run_characterize_foreground_cy(ui, preloaded_objects_per_analysis, static_preloaded_objects, low_memory=False):\n",
    "    if not low_memory:\n",
    "        ENSP_2_functionEnumArray_dict, year_arr, hierlevel_arr, entitytype_arr, functionalterm_arr, indices_arr, description_arr, category_arr, etype_2_minmax_funcEnum, function_enumeration_len, etype_cond_dict, etype_2_num_functions_dict, taxid_2_proteome_count, taxid_2_tuple_funcEnum_index_2_associations_counts, lineage_dict_enum, blacklisted_terms_bool_arr, cond_etypes_with_ontology, cond_etypes_rem_foreground_ids, kegg_taxid_2_acronym_dict, goslimtype_2_cond_dict = static_preloaded_objects\n",
    "    else:  # missing: ENSP_2_functionEnumArray_dict\n",
    "        year_arr, hierlevel_arr, entitytype_arr, functionalterm_arr, indices_arr, description_arr, category_arr, etype_2_minmax_funcEnum, function_enumeration_len, etype_cond_dict, etype_2_num_functions_dict, taxid_2_proteome_count, taxid_2_tuple_funcEnum_index_2_associations_counts, lineage_dict_enum, blacklisted_terms_bool_arr, cond_etypes_with_ontology, cond_etypes_rem_foreground_ids, kegg_taxid_2_acronym_dict, goslimtype_2_cond_dict = static_preloaded_objects\n",
    "    foreground_ids_arr_of_string, background_ids_arr_of_string, funcEnum_count_foreground, funcEnum_count_background, p_values, p_values_corrected, cond_multitest, blacklisted_terms_bool_arr_temp, cond_terms_reduced_with_ontology, cond_filter, cond_PMIDs, effectSizes, over_under_int_arr, over_under_arr_of_string = preloaded_objects_per_analysis\n",
    "    em = ui.enrichment_method\n",
    "    foreground_n = ui.get_foreground_n()\n",
    "    args_dict = ui.args_dict\n",
    "    filter_foreground_count_one = args_dict[\"filter_foreground_count_one\"]\n",
    "\n",
    "    protein_ans_fg = ui.get_foreground_an_set()\n",
    "    if low_memory:\n",
    "        ENSP_2_functionEnumArray_dict = query.get_functionEnumArray_from_proteins(ui.get_all_individual_AN(), dict_2_array=True)\n",
    "    ### add protein groups to ENSP_2_functionEnumArray_dict\n",
    "    ENSP_2_functionEnumArray_dict = add_protein_groups_to_ENSP_2_functionEnumArray_dict(ENSP_2_functionEnumArray_dict, ui.get_all_unique_proteinGroups())\n",
    "\n",
    "    ## count foreground\n",
    "    count_all_terms(ENSP_2_functionEnumArray_dict, protein_ans_fg, funcEnum_count_foreground)\n",
    "\n",
    "    ## limit to given entity types\n",
    "    cond_limit_2_entity_type = limit_to_entity_types(args_dict[\"limit_2_entity_type\"], function_enumeration_len, etype_cond_dict, funcEnum_count_foreground)\n",
    "    limit_to_go_subset(etype_cond_dict, args_dict[\"go_slim_subset\"], goslimtype_2_cond_dict, funcEnum_count_foreground)\n",
    "\n",
    "    ### calc ratio in foreground, count foreground / len(protein_ans)\n",
    "    ratio_in_foreground = funcEnum_count_foreground / foreground_n\n",
    "\n",
    "    ### concatenate filtered results\n",
    "    if filter_foreground_count_one:\n",
    "        cond_2_return = funcEnum_count_foreground > 1\n",
    "    else:\n",
    "        cond_2_return = funcEnum_count_foreground >= 1\n",
    "\n",
    "    ### limit PMID results\n",
    "    filter_PMID_top_n = args_dict[\"filter_PMID_top_n\"]\n",
    "    if filter_PMID_top_n is not None:\n",
    "        cond_PMID_2_filter = cond_2_return & etype_cond_dict[\"cond_56\"]\n",
    "        df_PMID = pd.DataFrame({\"foreground_count\": funcEnum_count_foreground[cond_PMID_2_filter].view(), \"year\": year_arr[cond_PMID_2_filter].view(), \"indices_arr\": indices_arr[cond_PMID_2_filter].view()})\n",
    "        indices_PMID = df_PMID.sort_values([\"foreground_count\", \"year\"], ascending=[False, False])[\"indices_arr\"].values[:filter_PMID_top_n]\n",
    "        # set all PMIDs to False and then include only those that were selected\n",
    "        cond_2_return[etype_cond_dict[\"cond_56\"]] = False\n",
    "        for index_ in indices_PMID:\n",
    "            cond_2_return[index_] = True\n",
    "    cond_2_return[blacklisted_terms_bool_arr > 0] = False\n",
    "\n",
    "    try:\n",
    "        privileged = args_dict[\"privileged\"]\n",
    "    except KeyError:\n",
    "        privileged = False\n",
    "    if not privileged:\n",
    "        # remove KEGG unless privileged\n",
    "        cond_kegg = etype_cond_dict[\"cond_52\"]\n",
    "        cond_2_return = cond_2_return & ~cond_kegg\n",
    "\n",
    "    funcEnum_indices_for_IDs = indices_arr[cond_2_return]\n",
    "    foreground_ids_arr_of_string = map_funcEnum_2_ENSPs(protein_ans_fg, ENSP_2_functionEnumArray_dict, funcEnum_indices_for_IDs, foreground_ids_arr_of_string)\n",
    "    if not low_memory:\n",
    "        df_2_return = pd.DataFrame({cn.term: functionalterm_arr[cond_2_return].view(),\n",
    "                                    cn.hierarchical_level: hierlevel_arr[cond_2_return].view(),\n",
    "                                    cn.category: category_arr[cond_2_return].view(),\n",
    "                                    cn.etype: entitytype_arr[cond_2_return].view(),\n",
    "                                    cn.description: description_arr[cond_2_return].view(),\n",
    "                                    cn.year: year_arr[cond_2_return].view(),\n",
    "                                    cn.ratio_in_FG: ratio_in_foreground[cond_2_return].view(),\n",
    "                                    cn.FG_IDs: foreground_ids_arr_of_string[cond_2_return].view(),\n",
    "                                    cn.FG_count: funcEnum_count_foreground[cond_2_return].view()})\n",
    "    else:\n",
    "        df_2_return = pd.DataFrame({cn.term: functionalterm_arr[cond_2_return].view(),\n",
    "                                    cn.hierarchical_level: hierlevel_arr[cond_2_return].view(),\n",
    "                                    cn.etype: entitytype_arr[cond_2_return].view(),\n",
    "                                    cn.year: year_arr[cond_2_return].view(),\n",
    "                                    cn.ratio_in_FG: ratio_in_foreground[cond_2_return].view(),\n",
    "                                    cn.FG_IDs: foreground_ids_arr_of_string[cond_2_return].view(),\n",
    "                                    cn.FG_count: funcEnum_count_foreground[cond_2_return].view(),\n",
    "                                    cn.funcEnum: indices_arr[cond_2_return].view()})\n",
    "        df_2_return[cn.category] = df_2_return[cn.etype].apply(lambda etype: variables.entityType_2_functionType_dict[etype])\n",
    "        funcEnum_2_description_dict = query.get_function_description_from_funcEnum(indices_arr[cond_2_return].tolist())\n",
    "        df_2_return[cn.description] = df_2_return[cn.funcEnum].apply(lambda funcEnum: funcEnum_2_description_dict[funcEnum])\n",
    "    df_2_return = ui.translate_primary_back_to_secondary(df_2_return)\n",
    "    df_2_return[cn.FG_n] = foreground_n\n",
    "    ### rank everything correctly except PMIDs, \"year\"-column will only affect PMIDs\n",
    "    df_2_return = df_2_return.sort_values([cn.etype, cn.year, cn.FG_count], ascending=[False, False, False]).reset_index(drop=True)\n",
    "    # debug delete me --> df_2_return = df_2_return.sort_values([cn.etype, \"s_value_abs\", cn.hierarchical_level, cn.year], ascending=[False, False, False, False])\n",
    "\n",
    "    if args_dict[\"STRING_beta\"]:\n",
    "        # return df_2_return[list(cn.cols_sort_order_characterize_foreground_STRING_beta)].rename(columns=cn.colnames_2_rename_dict_STRING_beta)\n",
    "        return df_2_return.rename(columns=cn.colnames_2_rename_dict_STRING_beta)[list(cn.cols_sort_order_characterize_foreground_STRING_beta)]\n",
    "    elif args_dict[\"STRING_API\"]:\n",
    "        df_2_return[\"ncbiTaxonId\"] = args_dict[\"taxid\"]\n",
    "        df_2_return[\"preferredNames\"] = \"\"\n",
    "        return df_2_return.rename(columns=cn.colnames_2_rename_dict_STRING_API)[list(cn.cols_sort_order_STRING_API_functional_annotation)]\n",
    "    cond_PMIDs = df_2_return[cn.etype] == -56\n",
    "    df_2_return.loc[~cond_PMIDs, cn.rank] = df_2_return[~cond_PMIDs].groupby(cn.etype)[cn.FG_count].rank(ascending=False, method=\"first\").fillna(value=df_2_return.shape[0])\n",
    "    df_2_return.loc[cond_PMIDs, cn.rank] = df_2_return[cond_PMIDs].groupby(cn.etype)[cn.year].rank(ascending=False, method=\"first\").fillna(value=df_2_return.shape[0])\n",
    "    df_2_return[cn.rank] = df_2_return[cn.rank].astype(int)\n",
    "    return df_2_return[list(cn.cols_2_return_run_characterize_foreground_cy)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run ze function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 21)\n",
      "category\n",
      "Gene Ontology biological process               1\n",
      "Gene Ontology cellular component               2\n",
      "Gene Ontology cellular component TEXTMINING    3\n",
      "Reactome                                       1\n",
      "UniProt keywords                               6\n",
      "Name: term, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(userinput)\n",
    "ENSP_2_tuple_funcEnum_score_dict = None\n",
    "\n",
    "contiguous = True\n",
    "foreground_n = 20\n",
    "foreground_input = sorted(get_random_human_ENSP(foreground_n, joined_for_web=False, contiguous=contiguous, UniProt_ID=True))\n",
    "# foreground_input = ['MEF2A_HUMAN', 'MEF2B_HUMAN', 'MEF2C_HUMAN', 'MEF2D_HUMAN', 'MEFV_HUMAN', 'MEG10_HUMAN', 'MEG11_HUMAN', 'MEGF6_HUMAN', 'MEGF8_HUMAN', 'MEGF9_HUMAN', 'MEI1_HUMAN', 'MEI4_HUMAN', 'MEIG1_HUMAN', 'MEIKN_HUMAN', 'MEIOB_HUMAN', 'MEIOC_HUMAN', 'MEIS1_HUMAN', 'MEIS2_HUMAN', 'MEIS3_HUMAN', 'MELK_HUMAN']\n",
    "from_file = False # read user input from file\n",
    "fn_userinput = r\"/Users/dblyon/modules/cpr/agotool/data/exampledata/Example_Yeast_acetylation_abundance_correction.txt\"\n",
    "# fn_userinput = r\"/Users/dblyon/Downloads/agotoolquestions/ClpP2up_KEimputed_aGOtool.txt\"\n",
    "# fn_userinput = r\"/Users/dblyon/modules/cpr/agotool/data/exampledata/Example_1_Yeast_acetylation_foreground_only.txt\"\n",
    "# fn_userinput = r\"/Users/dblyon/modules/cpr/agotool/data/exampledata/Example_1.1_Yeast_acetylation_without_abundance.txt\"\n",
    "\n",
    "enrichment_method = \"compare_samples\" # \"\" \"abundance_correction\" \"compare_samples\" \"genome\" \"compare_groups\"\n",
    "args_dict = {}\n",
    "args_dict[\"enrichment_method\"] = enrichment_method\n",
    "args_dict[\"taxid\"] = 9606 # 9606 # 559292 Yeast\n",
    "args_dict[\"FDR_cutoff\"] = 0.05\n",
    "args_dict[\"p_value_cutoff\"] = 0.01\n",
    "args_dict[\"limit_2_entity_type\"] = None # \"-20;-25;-26\" #\"-21;-22;-23;-51;-52;-53;-54;-55;-56-57;-58\"\n",
    "args_dict[\"filter_PMID_top_n\"] = 100\n",
    "args_dict[\"filter_foreground_count_one\"] = True\n",
    "args_dict[\"filter_parents\"] = True\n",
    "args_dict[\"go_slim_subset\"] = None # \"generic\"\n",
    "args_dict[\"o_or_u_or_both\"] = \"both\" # \"both\" \"underrepresented\" \"overrepresented\"\n",
    "args_dict[\"multiple_testing_per_etype\"] = True\n",
    "args_dict[\"privileged\"] = True\n",
    "args_dict[\"score_cutoff\"] = 0\n",
    "taxid = args_dict[\"taxid\"]\n",
    "debug = False\n",
    "profile = False\n",
    "simplified_output = False\n",
    "args_dict[\"simplified_output\"] = simplified_output\n",
    "args_dict[\"STRING_beta\"] = False\n",
    "# args_dict[\"multiple_testing_stringency\"] = \"A\"\n",
    "background_n = 300\n",
    "contiguous = True\n",
    "# background_input = sorted(get_random_human_ENSP(background_n, joined_for_web=False, contiguous=contiguous)) # background_input = ENSPs_homo\n",
    "# background_input = query.get_proteins_of_taxid(taxid, read_from_flat_files=True)\n",
    "# background_input = None\n",
    "\n",
    "### debug\n",
    "fn = r\"/Users/dblyon/Downloads/res.tsv\"\n",
    "df = pd.read_csv(fn, sep='\\t')\n",
    "fg = []\n",
    "for arr in df[\"foreground_ids\"].unique():\n",
    "    fg += arr.split(\";\")\n",
    "foreground_input = sorted(set(fg))\n",
    "\n",
    "bg = []\n",
    "for arr in df[\"background_ids\"].unique():\n",
    "    bg += arr.split(\";\")    \n",
    "background_input = sorted(set(bg))\n",
    "### debug\n",
    "\n",
    "\n",
    "if from_file:\n",
    "    ui = userinput.Userinput(pqo, fn_userinput, args_dict=args_dict)\n",
    "else:\n",
    "    ui = userinput.Userinput(pqo, fn=None, foreground_string=userinput.stringify_for_Userinput(foreground_input), background_string=userinput.stringify_for_Userinput(background_input), args_dict=args_dict)\n",
    "ncbi = pqo.ncbi\n",
    "preloaded_objects_per_analysis = pqo.get_preloaded_objects_per_analysis()\n",
    "\n",
    "if profile:\n",
    "    profile = line_profiler.LineProfiler(calc_pvalues_v2) # run_enrichment_cy, KolmogorovSmirnov_sparse_cy, KolmogorovSmirnov_sparse_cy_genome\n",
    "    profile.runcall(run_enrichment_cy, ENSP_2_tuple_funcEnum_score_dict, ncbi, ui, preloaded_objects_per_analysis, static_preloaded_objects, low_memory=True, debug=debug, KS_method=KS_method)\n",
    "    profile.print_stats()\n",
    "else:\n",
    "    if enrichment_method == \"characterize_foreground\":\n",
    "        df = run_characterize_foreground_cy(ui, preloaded_objects_per_analysis, static_preloaded_objects, low_memory=True)\n",
    "        df = df.sort_values([\"etype\", \"FG_count\"], ascending=[False, False])\n",
    "    else:\n",
    "        if debug:\n",
    "            df = run_enrichment_cy(ncbi, ui, preloaded_objects_per_analysis, static_preloaded_objects, low_memory=True, debug=debug)\n",
    "        else:\n",
    "            df = run_enrichment_cy(ncbi, ui, preloaded_objects_per_analysis, static_preloaded_objects, low_memory=True, debug=debug)\n",
    "#             funcEnum_count_foreground, funcEnum_count_background, foreground_n, background_n, p_values, cond_multitest, effectSizes, over_under_int_arr, o_or_u_or_both_encoding = run_enrichment_cy(ncbi, ui, preloaded_objects_per_analysis, static_preloaded_objects, low_memory=True, debug=debug, pvalue_version=\"debug\")\n",
    "            df = df.sort_values([\"etype\", \"rank\"], ascending=[False, True])\n",
    "            print(df.shape)\n",
    "            print(df.groupby(\"category\")[\"term\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>category</th>\n",
       "      <th>etype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOCC:0005576</td>\n",
       "      <td>Gene Ontology cellular component TEXTMINING</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GOCC:0031012</td>\n",
       "      <td>Gene Ontology cellular component TEXTMINING</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GOCC:0062023</td>\n",
       "      <td>Gene Ontology cellular component TEXTMINING</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GO:0030198</td>\n",
       "      <td>Gene Ontology biological process</td>\n",
       "      <td>-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GO:0031012</td>\n",
       "      <td>Gene Ontology cellular component</td>\n",
       "      <td>-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GO:0062023</td>\n",
       "      <td>Gene Ontology cellular component</td>\n",
       "      <td>-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KW-0964</td>\n",
       "      <td>UniProt keywords</td>\n",
       "      <td>-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KW-0732</td>\n",
       "      <td>UniProt keywords</td>\n",
       "      <td>-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KW-1015</td>\n",
       "      <td>UniProt keywords</td>\n",
       "      <td>-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KW-0325</td>\n",
       "      <td>UniProt keywords</td>\n",
       "      <td>-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KW-0272</td>\n",
       "      <td>UniProt keywords</td>\n",
       "      <td>-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KW-0245</td>\n",
       "      <td>UniProt keywords</td>\n",
       "      <td>-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>HSA-1474244</td>\n",
       "      <td>Reactome</td>\n",
       "      <td>-57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            term                                     category  etype\n",
       "0   GOCC:0005576  Gene Ontology cellular component TEXTMINING    -20\n",
       "1   GOCC:0031012  Gene Ontology cellular component TEXTMINING    -20\n",
       "2   GOCC:0062023  Gene Ontology cellular component TEXTMINING    -20\n",
       "3     GO:0030198             Gene Ontology biological process    -21\n",
       "4     GO:0031012             Gene Ontology cellular component    -22\n",
       "5     GO:0062023             Gene Ontology cellular component    -22\n",
       "6        KW-0964                             UniProt keywords    -51\n",
       "7        KW-0732                             UniProt keywords    -51\n",
       "8        KW-1015                             UniProt keywords    -51\n",
       "9        KW-0325                             UniProt keywords    -51\n",
       "10       KW-0272                             UniProt keywords    -51\n",
       "11       KW-0245                             UniProt keywords    -51\n",
       "12   HSA-1474244                                     Reactome    -57"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"term\", \"category\", \"etype\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>hierarchical_level</th>\n",
       "      <th>description</th>\n",
       "      <th>year</th>\n",
       "      <th>over_under</th>\n",
       "      <th>p_value</th>\n",
       "      <th>FDR</th>\n",
       "      <th>effect_size</th>\n",
       "      <th>ratio_in_foreground</th>\n",
       "      <th>ratio_in_background</th>\n",
       "      <th>...</th>\n",
       "      <th>foreground_n</th>\n",
       "      <th>background_count</th>\n",
       "      <th>background_n</th>\n",
       "      <th>foreground_ids</th>\n",
       "      <th>background_ids</th>\n",
       "      <th>s_value</th>\n",
       "      <th>rank</th>\n",
       "      <th>funcEnum</th>\n",
       "      <th>category</th>\n",
       "      <th>etype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOCC:0005576</td>\n",
       "      <td>2</td>\n",
       "      <td>Extracellular region</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>1.362150e-06</td>\n",
       "      <td>0.002672</td>\n",
       "      <td>0.338243</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0.290789</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>221</td>\n",
       "      <td>760</td>\n",
       "      <td>Q15582;P07858;P43235;Q9Y646;O00622;Q9Y240;P024...</td>\n",
       "      <td>Q13685;P60709;P63261;P06280;Q09666;P15121;P151...</td>\n",
       "      <td>1.984056</td>\n",
       "      <td>1</td>\n",
       "      <td>209</td>\n",
       "      <td>Gene Ontology cellular component TEXTMINING</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GOCC:0031012</td>\n",
       "      <td>4</td>\n",
       "      <td>Extracellular matrix</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>2.357761e-07</td>\n",
       "      <td>0.000925</td>\n",
       "      <td>0.218930</td>\n",
       "      <td>0.274194</td>\n",
       "      <td>0.055263</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>42</td>\n",
       "      <td>760</td>\n",
       "      <td>Q15582;O00622;P02452;P08123;P27658;Q9Y6C2;O959...</td>\n",
       "      <td>P08758;Q9UHI8;Q15582;O00622;P48509;P41208;P024...</td>\n",
       "      <td>1.450961</td>\n",
       "      <td>2</td>\n",
       "      <td>1023</td>\n",
       "      <td>Gene Ontology cellular component TEXTMINING</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GOCC:0062023</td>\n",
       "      <td>5</td>\n",
       "      <td>Collagen-containing extracellular matrix</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>1.417667e-06</td>\n",
       "      <td>0.002672</td>\n",
       "      <td>0.193251</td>\n",
       "      <td>0.241935</td>\n",
       "      <td>0.048684</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>37</td>\n",
       "      <td>760</td>\n",
       "      <td>Q15582;O00622;P02452;P08123;P27658;Q9Y6C2;O959...</td>\n",
       "      <td>P08758;Q15582;O00622;P48509;P41208;P02452;P081...</td>\n",
       "      <td>1.130216</td>\n",
       "      <td>3</td>\n",
       "      <td>2299</td>\n",
       "      <td>Gene Ontology cellular component TEXTMINING</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GO:0030198</td>\n",
       "      <td>5</td>\n",
       "      <td>extracellular matrix organization</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>2.963909e-07</td>\n",
       "      <td>0.005894</td>\n",
       "      <td>0.251528</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.071053</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>54</td>\n",
       "      <td>760</td>\n",
       "      <td>Q15582;P07384;P43235;O00622;P02452;P08123;P276...</td>\n",
       "      <td>Q9UHI8;Q15582;P07384;P43235;P07711;Q03135;O006...</td>\n",
       "      <td>1.642009</td>\n",
       "      <td>1</td>\n",
       "      <td>9384</td>\n",
       "      <td>Gene Ontology biological process</td>\n",
       "      <td>-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GO:0030312</td>\n",
       "      <td>4</td>\n",
       "      <td>external encapsulating structure</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>2.828384e-07</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.284126</td>\n",
       "      <td>0.370968</td>\n",
       "      <td>0.086842</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>66</td>\n",
       "      <td>760</td>\n",
       "      <td>Q15582;P07858;O00622;P02452;P08123;P27658;Q6UV...</td>\n",
       "      <td>P04083;P08758;Q9UHI8;Q15582;P27797;P07858;P536...</td>\n",
       "      <td>1.860586</td>\n",
       "      <td>1</td>\n",
       "      <td>24609</td>\n",
       "      <td>Gene Ontology cellular component</td>\n",
       "      <td>-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           term  hierarchical_level                               description  \\\n",
       "0  GOCC:0005576                   2                      Extracellular region   \n",
       "1  GOCC:0031012                   4                      Extracellular matrix   \n",
       "2  GOCC:0062023                   5  Collagen-containing extracellular matrix   \n",
       "3    GO:0030198                   5         extracellular matrix organization   \n",
       "4    GO:0030312                   4          external encapsulating structure   \n",
       "\n",
       "   year over_under       p_value       FDR  effect_size  ratio_in_foreground  \\\n",
       "0    -1          o  1.362150e-06  0.002672     0.338243             0.629032   \n",
       "1    -1          o  2.357761e-07  0.000925     0.218930             0.274194   \n",
       "2    -1          o  1.417667e-06  0.002672     0.193251             0.241935   \n",
       "3    -1          o  2.963909e-07  0.005894     0.251528             0.322581   \n",
       "4    -1          o  2.828384e-07  0.000781     0.284126             0.370968   \n",
       "\n",
       "   ratio_in_background  ...  foreground_n  background_count  background_n  \\\n",
       "0             0.290789  ...            62               221           760   \n",
       "1             0.055263  ...            62                42           760   \n",
       "2             0.048684  ...            62                37           760   \n",
       "3             0.071053  ...            62                54           760   \n",
       "4             0.086842  ...            62                66           760   \n",
       "\n",
       "                                      foreground_ids  \\\n",
       "0  Q15582;P07858;P43235;Q9Y646;O00622;Q9Y240;P024...   \n",
       "1  Q15582;O00622;P02452;P08123;P27658;Q9Y6C2;O959...   \n",
       "2  Q15582;O00622;P02452;P08123;P27658;Q9Y6C2;O959...   \n",
       "3  Q15582;P07384;P43235;O00622;P02452;P08123;P276...   \n",
       "4  Q15582;P07858;O00622;P02452;P08123;P27658;Q6UV...   \n",
       "\n",
       "                                      background_ids   s_value  rank  \\\n",
       "0  Q13685;P60709;P63261;P06280;Q09666;P15121;P151...  1.984056     1   \n",
       "1  P08758;Q9UHI8;Q15582;O00622;P48509;P41208;P024...  1.450961     2   \n",
       "2  P08758;Q15582;O00622;P48509;P41208;P02452;P081...  1.130216     3   \n",
       "3  Q9UHI8;Q15582;P07384;P43235;P07711;Q03135;O006...  1.642009     1   \n",
       "4  P04083;P08758;Q9UHI8;Q15582;P27797;P07858;P536...  1.860586     1   \n",
       "\n",
       "   funcEnum                                     category etype  \n",
       "0       209  Gene Ontology cellular component TEXTMINING   -20  \n",
       "1      1023  Gene Ontology cellular component TEXTMINING   -20  \n",
       "2      2299  Gene Ontology cellular component TEXTMINING   -20  \n",
       "3      9384             Gene Ontology biological process   -21  \n",
       "4     24609             Gene Ontology cellular component   -22  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "url_ = r\"https://agotool.org/api_orig\"\n",
    "\n",
    "fg = \"%0d\".join(foreground_input)\n",
    "bg = \"%0d\".join(background_input)\n",
    "result = requests.post(url_,\n",
    "                   params={\"output_format\": \"tsv\",\n",
    "                           \"enrichment_method\": \"compare_samples\"},\n",
    "                   data={\"foreground\": fg, \"background\": bg})\n",
    "df = pd.read_csv(StringIO(result.text), sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>hierarchical_level</th>\n",
       "      <th>description</th>\n",
       "      <th>year</th>\n",
       "      <th>over_under</th>\n",
       "      <th>p_value</th>\n",
       "      <th>FDR</th>\n",
       "      <th>effect_size</th>\n",
       "      <th>ratio_in_foreground</th>\n",
       "      <th>ratio_in_background</th>\n",
       "      <th>...</th>\n",
       "      <th>foreground_n</th>\n",
       "      <th>background_count</th>\n",
       "      <th>background_n</th>\n",
       "      <th>foreground_ids</th>\n",
       "      <th>background_ids</th>\n",
       "      <th>s_value</th>\n",
       "      <th>rank</th>\n",
       "      <th>funcEnum</th>\n",
       "      <th>category</th>\n",
       "      <th>etype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOCC:0005576</td>\n",
       "      <td>2</td>\n",
       "      <td>Extracellular region</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>1.362150e-06</td>\n",
       "      <td>0.002672</td>\n",
       "      <td>0.338243</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0.290789</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>221</td>\n",
       "      <td>760</td>\n",
       "      <td>Q15582;P07858;P43235;Q9Y646;O00622;Q9Y240;P024...</td>\n",
       "      <td>Q13685;P60709;P63261;P06280;Q09666;P15121;P151...</td>\n",
       "      <td>1.984056</td>\n",
       "      <td>1</td>\n",
       "      <td>209</td>\n",
       "      <td>Gene Ontology cellular component TEXTMINING</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GOCC:0031012</td>\n",
       "      <td>4</td>\n",
       "      <td>Extracellular matrix</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>2.357761e-07</td>\n",
       "      <td>0.000925</td>\n",
       "      <td>0.218930</td>\n",
       "      <td>0.274194</td>\n",
       "      <td>0.055263</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>42</td>\n",
       "      <td>760</td>\n",
       "      <td>Q15582;O00622;P02452;P08123;P27658;Q9Y6C2;O959...</td>\n",
       "      <td>P08758;Q9UHI8;Q15582;O00622;P48509;P41208;P024...</td>\n",
       "      <td>1.450961</td>\n",
       "      <td>2</td>\n",
       "      <td>1023</td>\n",
       "      <td>Gene Ontology cellular component TEXTMINING</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GOCC:0062023</td>\n",
       "      <td>5</td>\n",
       "      <td>Collagen-containing extracellular matrix</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>1.417667e-06</td>\n",
       "      <td>0.002672</td>\n",
       "      <td>0.193251</td>\n",
       "      <td>0.241935</td>\n",
       "      <td>0.048684</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>37</td>\n",
       "      <td>760</td>\n",
       "      <td>Q15582;O00622;P02452;P08123;P27658;Q9Y6C2;O959...</td>\n",
       "      <td>P08758;Q15582;O00622;P48509;P41208;P02452;P081...</td>\n",
       "      <td>1.130216</td>\n",
       "      <td>3</td>\n",
       "      <td>2299</td>\n",
       "      <td>Gene Ontology cellular component TEXTMINING</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GO:0030198</td>\n",
       "      <td>5</td>\n",
       "      <td>extracellular matrix organization</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>2.963909e-07</td>\n",
       "      <td>0.005894</td>\n",
       "      <td>0.251528</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.071053</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>54</td>\n",
       "      <td>760</td>\n",
       "      <td>Q15582;P07384;P43235;O00622;P02452;P08123;P276...</td>\n",
       "      <td>Q9UHI8;Q15582;P07384;P43235;P07711;Q03135;O006...</td>\n",
       "      <td>1.642009</td>\n",
       "      <td>1</td>\n",
       "      <td>9384</td>\n",
       "      <td>Gene Ontology biological process</td>\n",
       "      <td>-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GO:0030312</td>\n",
       "      <td>4</td>\n",
       "      <td>external encapsulating structure</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>2.828384e-07</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.284126</td>\n",
       "      <td>0.370968</td>\n",
       "      <td>0.086842</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>66</td>\n",
       "      <td>760</td>\n",
       "      <td>Q15582;P07858;O00622;P02452;P08123;P27658;Q6UV...</td>\n",
       "      <td>P04083;P08758;Q9UHI8;Q15582;P27797;P07858;P536...</td>\n",
       "      <td>1.860586</td>\n",
       "      <td>1</td>\n",
       "      <td>24609</td>\n",
       "      <td>Gene Ontology cellular component</td>\n",
       "      <td>-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GO:0031012</td>\n",
       "      <td>4</td>\n",
       "      <td>extracellular matrix</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>2.828384e-07</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.284126</td>\n",
       "      <td>0.370968</td>\n",
       "      <td>0.086842</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>66</td>\n",
       "      <td>760</td>\n",
       "      <td>Q15582;P07858;O00622;P02452;P08123;P27658;Q6UV...</td>\n",
       "      <td>P04083;P08758;Q9UHI8;Q15582;P27797;P07858;P536...</td>\n",
       "      <td>1.860586</td>\n",
       "      <td>2</td>\n",
       "      <td>24690</td>\n",
       "      <td>Gene Ontology cellular component</td>\n",
       "      <td>-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GO:0062023</td>\n",
       "      <td>5</td>\n",
       "      <td>collagen-containing extracellular matrix</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>1.149455e-06</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.261078</td>\n",
       "      <td>0.338710</td>\n",
       "      <td>0.077632</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>59</td>\n",
       "      <td>760</td>\n",
       "      <td>Q15582;P07858;O00622;P02452;P08123;P27658;Q6UV...</td>\n",
       "      <td>P04083;P08758;Q9UHI8;Q15582;P27797;P07858;P536...</td>\n",
       "      <td>1.550675</td>\n",
       "      <td>3</td>\n",
       "      <td>25722</td>\n",
       "      <td>Gene Ontology cellular component</td>\n",
       "      <td>-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KW-0964</td>\n",
       "      <td>2</td>\n",
       "      <td>Secreted</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>8.744909e-07</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.330560</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.121053</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>92</td>\n",
       "      <td>760</td>\n",
       "      <td>Q15582;P07858;P43235;Q9Y646;O00622;Q9Y240;P024...</td>\n",
       "      <td>Q9H4A4;P04083;Q9UHI8;P61769;Q15582;Q07021;P277...</td>\n",
       "      <td>2.002615</td>\n",
       "      <td>1</td>\n",
       "      <td>46784</td>\n",
       "      <td>UniProt keywords</td>\n",
       "      <td>-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KW-0732</td>\n",
       "      <td>2</td>\n",
       "      <td>Signal</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>1.171856e-04</td>\n",
       "      <td>0.034365</td>\n",
       "      <td>0.233531</td>\n",
       "      <td>0.467742</td>\n",
       "      <td>0.234211</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>178</td>\n",
       "      <td>760</td>\n",
       "      <td>Q15582;P07858;P43235;Q9Y646;O00622;Q9Y240;P024...</td>\n",
       "      <td>P06280;P30533;P20933;Q9UHI8;P61769;Q15582;P110...</td>\n",
       "      <td>0.918041</td>\n",
       "      <td>2</td>\n",
       "      <td>46569</td>\n",
       "      <td>UniProt keywords</td>\n",
       "      <td>-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KW-1015</td>\n",
       "      <td>2</td>\n",
       "      <td>Disulfide bond</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>1.171856e-04</td>\n",
       "      <td>0.034365</td>\n",
       "      <td>0.233531</td>\n",
       "      <td>0.467742</td>\n",
       "      <td>0.234211</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>178</td>\n",
       "      <td>760</td>\n",
       "      <td>Q15582;P07858;P43235;O00622;Q9Y240;P02452;P081...</td>\n",
       "      <td>P06280;P15144;P04083;P27695;P20933;Q9UHI8;P617...</td>\n",
       "      <td>0.918041</td>\n",
       "      <td>3</td>\n",
       "      <td>46835</td>\n",
       "      <td>UniProt keywords</td>\n",
       "      <td>-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KW-0325</td>\n",
       "      <td>2</td>\n",
       "      <td>Glycoprotein</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>1.854393e-04</td>\n",
       "      <td>0.036253</td>\n",
       "      <td>0.235526</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.264474</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>201</td>\n",
       "      <td>760</td>\n",
       "      <td>P07858;P43235;Q9Y646;Q9Y240;P02452;P08123;P025...</td>\n",
       "      <td>P33897;O00400;P06280;Q16352;P15144;P30533;P209...</td>\n",
       "      <td>0.878937</td>\n",
       "      <td>4</td>\n",
       "      <td>46207</td>\n",
       "      <td>UniProt keywords</td>\n",
       "      <td>-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KW-0272</td>\n",
       "      <td>3</td>\n",
       "      <td>Extracellular matrix</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>2.198246e-05</td>\n",
       "      <td>0.012893</td>\n",
       "      <td>0.154075</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.039474</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>30</td>\n",
       "      <td>760</td>\n",
       "      <td>Q15582;P02452;P08123;P27658;Q9Y6C2;O95967;Q9UB...</td>\n",
       "      <td>Q9UHI8;Q15582;P27797;P02452;P08123;P02462;P209...</td>\n",
       "      <td>0.717668</td>\n",
       "      <td>5</td>\n",
       "      <td>46159</td>\n",
       "      <td>UniProt keywords</td>\n",
       "      <td>-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KW-0245</td>\n",
       "      <td>2</td>\n",
       "      <td>EGF-like domain</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>2.618695e-05</td>\n",
       "      <td>0.012893</td>\n",
       "      <td>0.114559</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.014474</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>11</td>\n",
       "      <td>760</td>\n",
       "      <td>Q14517;O95967;Q9UBX5;P35555;Q14767;P98160;P354...</td>\n",
       "      <td>P78357;Q14517;O95967;Q9UBX5;P35555;Q07954;Q147...</td>\n",
       "      <td>0.524898</td>\n",
       "      <td>6</td>\n",
       "      <td>46139</td>\n",
       "      <td>UniProt keywords</td>\n",
       "      <td>-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HSA-1474244</td>\n",
       "      <td>1</td>\n",
       "      <td>Extracellular matrix organization</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>3.755617e-07</td>\n",
       "      <td>0.007329</td>\n",
       "      <td>0.250212</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.072368</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>55</td>\n",
       "      <td>760</td>\n",
       "      <td>P07384;P07858;P43235;P02452;P08123;P27658;Q9Y6...</td>\n",
       "      <td>P12814;Q9UHI8;P07384;P42574;P07858;P07339;P432...</td>\n",
       "      <td>1.607693</td>\n",
       "      <td>1</td>\n",
       "      <td>3562617</td>\n",
       "      <td>Reactome</td>\n",
       "      <td>-57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            term  hierarchical_level  \\\n",
       "0   GOCC:0005576                   2   \n",
       "1   GOCC:0031012                   4   \n",
       "2   GOCC:0062023                   5   \n",
       "3     GO:0030198                   5   \n",
       "4     GO:0030312                   4   \n",
       "5     GO:0031012                   4   \n",
       "6     GO:0062023                   5   \n",
       "7        KW-0964                   2   \n",
       "8        KW-0732                   2   \n",
       "9        KW-1015                   2   \n",
       "10       KW-0325                   2   \n",
       "11       KW-0272                   3   \n",
       "12       KW-0245                   2   \n",
       "13   HSA-1474244                   1   \n",
       "\n",
       "                                 description  year over_under       p_value  \\\n",
       "0                       Extracellular region    -1          o  1.362150e-06   \n",
       "1                       Extracellular matrix    -1          o  2.357761e-07   \n",
       "2   Collagen-containing extracellular matrix    -1          o  1.417667e-06   \n",
       "3          extracellular matrix organization    -1          o  2.963909e-07   \n",
       "4           external encapsulating structure    -1          o  2.828384e-07   \n",
       "5                       extracellular matrix    -1          o  2.828384e-07   \n",
       "6   collagen-containing extracellular matrix    -1          o  1.149455e-06   \n",
       "7                                   Secreted    -1          o  8.744909e-07   \n",
       "8                                     Signal    -1          o  1.171856e-04   \n",
       "9                             Disulfide bond    -1          o  1.171856e-04   \n",
       "10                              Glycoprotein    -1          o  1.854393e-04   \n",
       "11                      Extracellular matrix    -1          o  2.198246e-05   \n",
       "12                           EGF-like domain    -1          o  2.618695e-05   \n",
       "13         Extracellular matrix organization    -1          o  3.755617e-07   \n",
       "\n",
       "         FDR  effect_size  ratio_in_foreground  ratio_in_background  ...  \\\n",
       "0   0.002672     0.338243             0.629032             0.290789  ...   \n",
       "1   0.000925     0.218930             0.274194             0.055263  ...   \n",
       "2   0.002672     0.193251             0.241935             0.048684  ...   \n",
       "3   0.005894     0.251528             0.322581             0.071053  ...   \n",
       "4   0.000781     0.284126             0.370968             0.086842  ...   \n",
       "5   0.000781     0.284126             0.370968             0.086842  ...   \n",
       "6   0.001058     0.261078             0.338710             0.077632  ...   \n",
       "7   0.001026     0.330560             0.451613             0.121053  ...   \n",
       "8   0.034365     0.233531             0.467742             0.234211  ...   \n",
       "9   0.034365     0.233531             0.467742             0.234211  ...   \n",
       "10  0.036253     0.235526             0.500000             0.264474  ...   \n",
       "11  0.012893     0.154075             0.193548             0.039474  ...   \n",
       "12  0.012893     0.114559             0.129032             0.014474  ...   \n",
       "13  0.007329     0.250212             0.322581             0.072368  ...   \n",
       "\n",
       "    foreground_n  background_count  background_n  \\\n",
       "0             62               221           760   \n",
       "1             62                42           760   \n",
       "2             62                37           760   \n",
       "3             62                54           760   \n",
       "4             62                66           760   \n",
       "5             62                66           760   \n",
       "6             62                59           760   \n",
       "7             62                92           760   \n",
       "8             62               178           760   \n",
       "9             62               178           760   \n",
       "10            62               201           760   \n",
       "11            62                30           760   \n",
       "12            62                11           760   \n",
       "13            62                55           760   \n",
       "\n",
       "                                       foreground_ids  \\\n",
       "0   Q15582;P07858;P43235;Q9Y646;O00622;Q9Y240;P024...   \n",
       "1   Q15582;O00622;P02452;P08123;P27658;Q9Y6C2;O959...   \n",
       "2   Q15582;O00622;P02452;P08123;P27658;Q9Y6C2;O959...   \n",
       "3   Q15582;P07384;P43235;O00622;P02452;P08123;P276...   \n",
       "4   Q15582;P07858;O00622;P02452;P08123;P27658;Q6UV...   \n",
       "5   Q15582;P07858;O00622;P02452;P08123;P27658;Q6UV...   \n",
       "6   Q15582;P07858;O00622;P02452;P08123;P27658;Q6UV...   \n",
       "7   Q15582;P07858;P43235;Q9Y646;O00622;Q9Y240;P024...   \n",
       "8   Q15582;P07858;P43235;Q9Y646;O00622;Q9Y240;P024...   \n",
       "9   Q15582;P07858;P43235;O00622;Q9Y240;P02452;P081...   \n",
       "10  P07858;P43235;Q9Y646;Q9Y240;P02452;P08123;P025...   \n",
       "11  Q15582;P02452;P08123;P27658;Q9Y6C2;O95967;Q9UB...   \n",
       "12  Q14517;O95967;Q9UBX5;P35555;Q14767;P98160;P354...   \n",
       "13  P07384;P07858;P43235;P02452;P08123;P27658;Q9Y6...   \n",
       "\n",
       "                                       background_ids   s_value  rank  \\\n",
       "0   Q13685;P60709;P63261;P06280;Q09666;P15121;P151...  1.984056     1   \n",
       "1   P08758;Q9UHI8;Q15582;O00622;P48509;P41208;P024...  1.450961     2   \n",
       "2   P08758;Q15582;O00622;P48509;P41208;P02452;P081...  1.130216     3   \n",
       "3   Q9UHI8;Q15582;P07384;P43235;P07711;Q03135;O006...  1.642009     1   \n",
       "4   P04083;P08758;Q9UHI8;Q15582;P27797;P07858;P536...  1.860586     1   \n",
       "5   P04083;P08758;Q9UHI8;Q15582;P27797;P07858;P536...  1.860586     2   \n",
       "6   P04083;P08758;Q9UHI8;Q15582;P27797;P07858;P536...  1.550675     3   \n",
       "7   Q9H4A4;P04083;Q9UHI8;P61769;Q15582;Q07021;P277...  2.002615     1   \n",
       "8   P06280;P30533;P20933;Q9UHI8;P61769;Q15582;P110...  0.918041     2   \n",
       "9   P06280;P15144;P04083;P27695;P20933;Q9UHI8;P617...  0.918041     3   \n",
       "10  P33897;O00400;P06280;Q16352;P15144;P30533;P209...  0.878937     4   \n",
       "11  Q9UHI8;Q15582;P27797;P02452;P08123;P02462;P209...  0.717668     5   \n",
       "12  P78357;Q14517;O95967;Q9UBX5;P35555;Q07954;Q147...  0.524898     6   \n",
       "13  P12814;Q9UHI8;P07384;P42574;P07858;P07339;P432...  1.607693     1   \n",
       "\n",
       "    funcEnum                                     category etype  \n",
       "0        209  Gene Ontology cellular component TEXTMINING   -20  \n",
       "1       1023  Gene Ontology cellular component TEXTMINING   -20  \n",
       "2       2299  Gene Ontology cellular component TEXTMINING   -20  \n",
       "3       9384             Gene Ontology biological process   -21  \n",
       "4      24609             Gene Ontology cellular component   -22  \n",
       "5      24690             Gene Ontology cellular component   -22  \n",
       "6      25722             Gene Ontology cellular component   -22  \n",
       "7      46784                             UniProt keywords   -51  \n",
       "8      46569                             UniProt keywords   -51  \n",
       "9      46835                             UniProt keywords   -51  \n",
       "10     46207                             UniProt keywords   -51  \n",
       "11     46159                             UniProt keywords   -51  \n",
       "12     46139                             UniProt keywords   -51  \n",
       "13   3562617                                     Reactome   -57  \n",
       "\n",
       "[14 rows x 21 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 20)\n",
      "category\n",
      "Gene Ontology cellular component               25\n",
      "Gene Ontology cellular component TEXTMINING    16\n",
      "UniProt keywords                               12\n",
      "Name: term, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(userinput)\n",
    "ENSP_2_tuple_funcEnum_score_dict = None\n",
    "#######################\n",
    "### examples\n",
    "# foreground_input = [\"HBA_HUMAN\", \"HBB_HUMAN\", \"HBD_HUMAN\", \"HBE_HUMAN\"] # example 1: Human hemoglobin, genome\n",
    "# example 2: Yeast acetylation, abundance_correction. Example_1_Yeast_acetylation_abundance_correction.txt\n",
    "# example 3: compare_samples\n",
    "# human plasma liver cirrhosis Lili Niu\n",
    "# foreground_input = ['P05062;A0A024R145;A8K430;A0A087WXX2;Q8NHT3', 'Q08380;B4DVE1;A0A0S2Z3Y1;B3KP88;B4DDG4;B4DWA8;B4DI70', 'P04004;D9ZGG2;B7Z553', 'O95445', 'P01833', 'P43652', 'Q5SRP5']\n",
    "# mouse Insulin (STRING network )\n",
    "# foreground_input = ['10090.ENSMUSP00000005671', '10090.ENSMUSP00000020846', '10090.ENSMUSP00000022921', '10090.ENSMUSP00000028252', '10090.ENSMUSP00000056668', '10090.ENSMUSP00000061877', '10090.ENSMUSP00000084464', '10090.ENSMUSP00000088837', '10090.ENSMUSP00000099787', '10090.ENSMUSP00000099862', '10090.ENSMUSP00000104298']\n",
    "# mouse interferon (STRING network)\n",
    "# foreground_input = ['10090.ENSMUSP00000001036', '10090.ENSMUSP00000023689', '10090.ENSMUSP00000023693', '10090.ENSMUSP00000038121', '10090.ENSMUSP00000056720', '10090.ENSMUSP00000066743', '10090.ENSMUSP00000092581', '10090.ENSMUSP00000099842', '10090.ENSMUSP00000100872', '10090.ENSMUSP00000120525', '10090.ENSMUSP00000127921']\n",
    "#Q9R117\\nP33896\\nO35664\\nO35716\\nP01575\\nP42225\\nP07351\\nP52332\\nQ9WVL2\\nQ61179\\nQ61716\n",
    "# foreground_input = [\"ADH1_YEAST\", \"PDC1_YEAST\", \"PFKA1_YEAST\"]\n",
    "# foreground_input = [\"PGM1_YEAST\", \"G6PI_YEAST\", \"PMG2_YEAST\", \"CISY2_YEAST\"]\n",
    "############\n",
    "contiguous = True\n",
    "foreground_n = 300\n",
    "# foreground_input = sorted(get_random_human_ENSP(foreground_n, joined_for_web=False, contiguous=contiguous, UniProt_ID=True))\n",
    "# foreground_input = ['MEF2A_HUMAN', 'MEF2B_HUMAN', 'MEF2C_HUMAN', 'MEF2D_HUMAN', 'MEFV_HUMAN', 'MEG10_HUMAN', 'MEG11_HUMAN', 'MEGF6_HUMAN', 'MEGF8_HUMAN', 'MEGF9_HUMAN', 'MEI1_HUMAN', 'MEI4_HUMAN', 'MEIG1_HUMAN', 'MEIKN_HUMAN', 'MEIOB_HUMAN', 'MEIOC_HUMAN', 'MEIS1_HUMAN', 'MEIS2_HUMAN', 'MEIS3_HUMAN', 'MELK_HUMAN']\n",
    "from_file = True # read user input from file\n",
    "fn_userinput = r\"/Users/dblyon/modules/cpr/agotool/data/exampledata/Example_Yeast_acetylation_abundance_correction.txt\"\n",
    "# fn_userinput = r\"/Users/dblyon/Downloads/agotoolquestions/ClpP2up_KEimputed_aGOtool.txt\"\n",
    "# fn_userinput = r\"/Users/dblyon/modules/cpr/agotool/data/exampledata/Example_1_Yeast_acetylation_foreground_only.txt\"\n",
    "# fn_userinput = r\"/Users/dblyon/modules/cpr/agotool/data/exampledata/Example_1.1_Yeast_acetylation_without_abundance.txt\"\n",
    "# foreground_input = [\"P69905\"]\n",
    "# foreground_input = corona\n",
    "\n",
    "enrichment_method = \"compare_samples\" # \"\" \"abundance_correction\" \"compare_samples\" \"genome\"\n",
    "args_dict = {}\n",
    "args_dict[\"enrichment_method\"] = enrichment_method\n",
    "args_dict[\"taxid\"] = 9606 # 9606 # 559292 Yeast\n",
    "args_dict[\"FDR_cutoff\"] = 0.05\n",
    "args_dict[\"p_value_cutoff\"] = 0.01\n",
    "args_dict[\"limit_2_entity_type\"] = None # \"-20;-25;-26\" #\"-21;-22;-23;-51;-52;-53;-54;-55;-56-57;-58\"\n",
    "args_dict[\"filter_PMID_top_n\"] = 100\n",
    "args_dict[\"filter_foreground_count_one\"] = True\n",
    "args_dict[\"filter_parents\"] = True\n",
    "args_dict[\"go_slim_subset\"] = None # \"generic\"\n",
    "args_dict[\"o_or_u_or_both\"] = \"both\" # \"both\" \"underrepresented\" \"overrepresented\"\n",
    "args_dict[\"multiple_testing_per_etype\"] = True\n",
    "args_dict[\"privileged\"] = True\n",
    "args_dict[\"score_cutoff\"] = 0\n",
    "# args_dict[\"foreground_replicates\"] = 10\n",
    "# args_dict[\"background_replicates\"] = 10\n",
    "taxid = args_dict[\"taxid\"]\n",
    "debug = False\n",
    "profile = False\n",
    "simplified_output = False\n",
    "args_dict[\"simplified_output\"] = simplified_output\n",
    "args_dict[\"STRING_beta\"] = False\n",
    "# KS_method = \"sparse_scipy\" # {\"scipy\", \"cy\", \"sparse_scipy\"}\n",
    "background_n = 300\n",
    "contiguous = True\n",
    "# background_input = sorted(get_random_human_ENSP(background_n, joined_for_web=False, contiguous=contiguous)) # background_input = ENSPs_homo\n",
    "# background_input = query.get_proteins_of_taxid(taxid, read_from_flat_files=True)\n",
    "# background_input = None\n",
    "if from_file:\n",
    "    ui = userinput.Userinput(pqo, fn_userinput, args_dict=args_dict)\n",
    "else:\n",
    "    ui = userinput.Userinput(pqo, fn=None, foreground_string=userinput.stringify_for_Userinput(foreground_input), background_string=userinput.stringify_for_Userinput(background_input), args_dict=args_dict)\n",
    "ncbi = pqo.ncbi\n",
    "preloaded_objects_per_analysis = pqo.get_preloaded_objects_per_analysis()\n",
    "\n",
    "if profile:\n",
    "    profile = line_profiler.LineProfiler(calc_pvalues_v2) # run_enrichment_cy, KolmogorovSmirnov_sparse_cy, KolmogorovSmirnov_sparse_cy_genome\n",
    "    profile.runcall(run_enrichment_cy, ENSP_2_tuple_funcEnum_score_dict, ncbi, ui, preloaded_objects_per_analysis, static_preloaded_objects, low_memory=True, debug=debug, KS_method=KS_method)\n",
    "    profile.print_stats()\n",
    "else:\n",
    "    if enrichment_method == \"characterize_foreground\":\n",
    "        df = run_characterize_foreground_cy(ui, preloaded_objects_per_analysis, static_preloaded_objects, low_memory=True)\n",
    "        df = df.sort_values([\"etype\", \"FG_count\"], ascending=[False, False])\n",
    "    else:\n",
    "        if debug:\n",
    "            df = run_enrichment_cy(ncbi, ui, preloaded_objects_per_analysis, static_preloaded_objects, low_memory=True, debug=debug)\n",
    "        else:\n",
    "            df = run_enrichment_cy(ncbi, ui, preloaded_objects_per_analysis, static_preloaded_objects, low_memory=True, debug=debug)\n",
    "#             funcEnum_count_foreground, funcEnum_count_background, foreground_n, background_n, p_values, cond_multitest, effectSizes, over_under_int_arr, o_or_u_or_both_encoding = run_enrichment_cy(ncbi, ui, preloaded_objects_per_analysis, static_preloaded_objects, low_memory=True, debug=debug, pvalue_version=\"debug\")\n",
    "            df = df.sort_values([\"etype\", \"rank\"], ascending=[False, True])\n",
    "            print(df.shape)\n",
    "            print(df.groupby(\"category\")[\"term\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.copy()\n",
    "# df_new[\"effect_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((56, 20), (56, 20))"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_old.shape, df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "Gene Ontology cellular component               25\n",
       "Gene Ontology cellular component TEXTMINING    19\n",
       "UniProt keywords                               12\n",
       "Name: term, dtype: int64"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_old.groupby(\"category\")[\"term\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "Gene Ontology cellular component               25\n",
       "Gene Ontology cellular component TEXTMINING    19\n",
       "UniProt keywords                               12\n",
       "Name: term, dtype: int64"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.groupby(\"category\")[\"term\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>hierarchical_level</th>\n",
       "      <th>description</th>\n",
       "      <th>year</th>\n",
       "      <th>over_under</th>\n",
       "      <th>p_value</th>\n",
       "      <th>FDR</th>\n",
       "      <th>effect_size</th>\n",
       "      <th>ratio_in_foreground</th>\n",
       "      <th>ratio_in_background</th>\n",
       "      <th>foreground_count</th>\n",
       "      <th>foreground_n</th>\n",
       "      <th>background_count</th>\n",
       "      <th>background_n</th>\n",
       "      <th>foreground_ids</th>\n",
       "      <th>s_value</th>\n",
       "      <th>rank</th>\n",
       "      <th>funcEnum</th>\n",
       "      <th>category</th>\n",
       "      <th>etype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>KW-0238</td>\n",
       "      <td>2</td>\n",
       "      <td>DNA-binding</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.021388</td>\n",
       "      <td>0.037964</td>\n",
       "      <td>0.082830</td>\n",
       "      <td>0.044866</td>\n",
       "      <td>96</td>\n",
       "      <td>1159</td>\n",
       "      <td>52</td>\n",
       "      <td>1159</td>\n",
       "      <td>P14164;Q02486;P40535;P07248;P41696;P22035;P171...</td>\n",
       "      <td>0.137640</td>\n",
       "      <td>8</td>\n",
       "      <td>46776</td>\n",
       "      <td>UniProt keywords</td>\n",
       "      <td>-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>KW-0698</td>\n",
       "      <td>2</td>\n",
       "      <td>rRNA processing</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.021388</td>\n",
       "      <td>0.036238</td>\n",
       "      <td>0.075928</td>\n",
       "      <td>0.039689</td>\n",
       "      <td>88</td>\n",
       "      <td>1159</td>\n",
       "      <td>46</td>\n",
       "      <td>1159</td>\n",
       "      <td>P40493;P25627;P33322;Q12389;P24783;P20447;P204...</td>\n",
       "      <td>0.131291</td>\n",
       "      <td>9</td>\n",
       "      <td>47186</td>\n",
       "      <td>UniProt keywords</td>\n",
       "      <td>-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>KW-0732</td>\n",
       "      <td>2</td>\n",
       "      <td>Signal</td>\n",
       "      <td>-1</td>\n",
       "      <td>u</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.003653</td>\n",
       "      <td>-0.024159</td>\n",
       "      <td>0.007765</td>\n",
       "      <td>0.031924</td>\n",
       "      <td>9</td>\n",
       "      <td>1159</td>\n",
       "      <td>37</td>\n",
       "      <td>1159</td>\n",
       "      <td>P25371;P37302;P16474;Q06350;P43555;Q12408;P179...</td>\n",
       "      <td>-0.107883</td>\n",
       "      <td>10</td>\n",
       "      <td>47213</td>\n",
       "      <td>UniProt keywords</td>\n",
       "      <td>-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>KW-0156</td>\n",
       "      <td>2</td>\n",
       "      <td>Chromatin regulator</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.006653</td>\n",
       "      <td>0.025022</td>\n",
       "      <td>0.035375</td>\n",
       "      <td>0.010354</td>\n",
       "      <td>41</td>\n",
       "      <td>1159</td>\n",
       "      <td>12</td>\n",
       "      <td>1159</td>\n",
       "      <td>P80428;Q05123;P32447;Q07457;P32657;Q08923;P313...</td>\n",
       "      <td>0.104276</td>\n",
       "      <td>11</td>\n",
       "      <td>46701</td>\n",
       "      <td>UniProt keywords</td>\n",
       "      <td>-51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>KW-0010</td>\n",
       "      <td>2</td>\n",
       "      <td>Activator</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.028194</td>\n",
       "      <td>0.025884</td>\n",
       "      <td>0.043141</td>\n",
       "      <td>0.017256</td>\n",
       "      <td>50</td>\n",
       "      <td>1159</td>\n",
       "      <td>20</td>\n",
       "      <td>1159</td>\n",
       "      <td>P14164;P07248;P80428;P22035;P14066;Q06697;P891...</td>\n",
       "      <td>0.089131</td>\n",
       "      <td>12</td>\n",
       "      <td>46569</td>\n",
       "      <td>UniProt keywords</td>\n",
       "      <td>-51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       term  hierarchical_level          description  year over_under  \\\n",
       "51  KW-0238                   2          DNA-binding    -1          o   \n",
       "52  KW-0698                   2      rRNA processing    -1          o   \n",
       "53  KW-0732                   2               Signal    -1          u   \n",
       "54  KW-0156                   2  Chromatin regulator    -1          o   \n",
       "55  KW-0010                   2            Activator    -1          o   \n",
       "\n",
       "     p_value       FDR  effect_size  ratio_in_foreground  ratio_in_background  \\\n",
       "51  0.000237  0.021388     0.037964             0.082830             0.044866   \n",
       "52  0.000238  0.021388     0.036238             0.075928             0.039689   \n",
       "53  0.000034  0.003653    -0.024159             0.007765             0.031924   \n",
       "54  0.000068  0.006653     0.025022             0.035375             0.010354   \n",
       "55  0.000360  0.028194     0.025884             0.043141             0.017256   \n",
       "\n",
       "    foreground_count  foreground_n  background_count  background_n  \\\n",
       "51                96          1159                52          1159   \n",
       "52                88          1159                46          1159   \n",
       "53                 9          1159                37          1159   \n",
       "54                41          1159                12          1159   \n",
       "55                50          1159                20          1159   \n",
       "\n",
       "                                       foreground_ids   s_value  rank  \\\n",
       "51  P14164;Q02486;P40535;P07248;P41696;P22035;P171...  0.137640     8   \n",
       "52  P40493;P25627;P33322;Q12389;P24783;P20447;P204...  0.131291     9   \n",
       "53  P25371;P37302;P16474;Q06350;P43555;Q12408;P179... -0.107883    10   \n",
       "54  P80428;Q05123;P32447;Q07457;P32657;Q08923;P313...  0.104276    11   \n",
       "55  P14164;P07248;P80428;P22035;P14066;Q06697;P891...  0.089131    12   \n",
       "\n",
       "    funcEnum          category  etype  \n",
       "51     46776  UniProt keywords    -51  \n",
       "52     47186  UniProt keywords    -51  \n",
       "53     47213  UniProt keywords    -51  \n",
       "54     46701  UniProt keywords    -51  \n",
       "55     46569  UniProt keywords    -51  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_old.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import testing as pd_testing\n",
    "pd_testing.assert_frame_equal(df_old, df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>hierarchical_level</th>\n",
       "      <th>description</th>\n",
       "      <th>year</th>\n",
       "      <th>over_under</th>\n",
       "      <th>p_value</th>\n",
       "      <th>FDR</th>\n",
       "      <th>effect_size</th>\n",
       "      <th>ratio_in_foreground</th>\n",
       "      <th>ratio_in_background</th>\n",
       "      <th>foreground_count</th>\n",
       "      <th>foreground_n</th>\n",
       "      <th>background_count</th>\n",
       "      <th>background_n</th>\n",
       "      <th>foreground_ids</th>\n",
       "      <th>s_value</th>\n",
       "      <th>rank</th>\n",
       "      <th>funcEnum</th>\n",
       "      <th>category</th>\n",
       "      <th>etype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>KW-0010</td>\n",
       "      <td>2</td>\n",
       "      <td>Activator</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.028194</td>\n",
       "      <td>0.025884</td>\n",
       "      <td>0.043141</td>\n",
       "      <td>0.017256</td>\n",
       "      <td>50</td>\n",
       "      <td>1159</td>\n",
       "      <td>20</td>\n",
       "      <td>1159</td>\n",
       "      <td>P14164;P07248;P80428;P22035;P14066;Q06697;P891...</td>\n",
       "      <td>0.089131</td>\n",
       "      <td>12</td>\n",
       "      <td>46569</td>\n",
       "      <td>UniProt keywords</td>\n",
       "      <td>-51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       term  hierarchical_level description  year over_under  p_value  \\\n",
       "55  KW-0010                   2   Activator    -1          o  0.00036   \n",
       "\n",
       "         FDR  effect_size  ratio_in_foreground  ratio_in_background  \\\n",
       "55  0.028194     0.025884             0.043141             0.017256   \n",
       "\n",
       "    foreground_count  foreground_n  background_count  background_n  \\\n",
       "55                50          1159                20          1159   \n",
       "\n",
       "                                       foreground_ids   s_value  rank  \\\n",
       "55  P14164;P07248;P80428;P22035;P14066;Q06697;P891...  0.089131    12   \n",
       "\n",
       "    funcEnum          category  etype  \n",
       "55     46569  UniProt keywords    -51  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term = \"KW-0010\"\n",
    "df_old[df_old[\"term\"] == term].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>hierarchical_level</th>\n",
       "      <th>description</th>\n",
       "      <th>year</th>\n",
       "      <th>over_under</th>\n",
       "      <th>p_value</th>\n",
       "      <th>FDR</th>\n",
       "      <th>effect_size</th>\n",
       "      <th>ratio_in_foreground</th>\n",
       "      <th>ratio_in_background</th>\n",
       "      <th>foreground_count</th>\n",
       "      <th>foreground_n</th>\n",
       "      <th>background_count</th>\n",
       "      <th>background_n</th>\n",
       "      <th>foreground_ids</th>\n",
       "      <th>s_value</th>\n",
       "      <th>rank</th>\n",
       "      <th>funcEnum</th>\n",
       "      <th>category</th>\n",
       "      <th>etype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>KW-0010</td>\n",
       "      <td>2</td>\n",
       "      <td>Activator</td>\n",
       "      <td>-1</td>\n",
       "      <td>o</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.028194</td>\n",
       "      <td>0.025884</td>\n",
       "      <td>0.043141</td>\n",
       "      <td>0.017256</td>\n",
       "      <td>50</td>\n",
       "      <td>1159</td>\n",
       "      <td>20</td>\n",
       "      <td>1159</td>\n",
       "      <td>P14164;P07248;P80428;P22035;P14066;Q06697;P891...</td>\n",
       "      <td>0.089131</td>\n",
       "      <td>12</td>\n",
       "      <td>46569</td>\n",
       "      <td>UniProt keywords</td>\n",
       "      <td>-51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       term  hierarchical_level description  year over_under  p_value  \\\n",
       "55  KW-0010                   2   Activator    -1          o  0.00036   \n",
       "\n",
       "         FDR  effect_size  ratio_in_foreground  ratio_in_background  \\\n",
       "55  0.028194     0.025884             0.043141             0.017256   \n",
       "\n",
       "    foreground_count  foreground_n  background_count  background_n  \\\n",
       "55                50          1159                20          1159   \n",
       "\n",
       "                                       foreground_ids   s_value  rank  \\\n",
       "55  P14164;P07248;P80428;P22035;P14066;Q06697;P891...  0.089131    12   \n",
       "\n",
       "    funcEnum          category  etype  \n",
       "55     46569  UniProt keywords    -51  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new[df_new[\"term\"] == term].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'userinput' from '/Users/dblyon/modules/cpr/agotool/app/python/userinput.py'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(userinput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "taxid = random.choice(query.get_taxids())\n",
    "background = query.get_proteins_of_taxid(taxid)\n",
    "foreground = random.sample(background, 200)\n",
    "intensity = [str(ele) for ele in np.random.normal(size=len(background))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53012"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.15 + 0.09722 + 0.0689 + 0.107 + 0.107"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(missingScores_list), missingScores_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_list_sparse, scores_list_ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_userinput = os.path.join(variables.EXAMPLE_FOLDER, \"Example_1_Yeast_acetylation_abundance_correction.txt\")\n",
    "df = pd.read_csv(fn_userinput, sep='\\t')\n",
    "fg = df.loc[df[\"Foreground\"].notnull(), \"Foreground\"].tolist()\n",
    "d = list(query.map_secondary_2_primary_ANs(fg).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprotid = 'YD21B_YEAST'\n",
    "ENSP_2_tuple_funcEnum_score_dict[\"ARV1_ARATH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.to_csv(\"~/Downloads/Example_1_Yeast_acetylation_abundance_correction_OUTPUT_SCIPY.txt\", sep=\"\\t\", header=True, index=False)\n",
    "dfc.to_csv(\"~/Downloads/Example_1_Yeast_acetylation_abundance_correction_OUTPUT_CYTHON.txt\", sep=\"\\t\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(ENSP_2_tuple_funcEnum_score_dict.keys())[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(fg), len(set(fg)))\n",
    "fg[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = fg_scores_matrix_data\n",
    "# indptr = fg_scores_matrix_indptr\n",
    "# for i in range(len(indptr[:-1])):  # get column values\n",
    "#     index_row_start = indptr[i]\n",
    "#     index_row_stop = indptr[i + 1]\n",
    "#     if index_row_start == index_row_stop:\n",
    "#         continue\n",
    "#     funcEnum = i\n",
    "#     scores_list_sparse = sorted(data[index_row_start:index_row_stop])\n",
    "#     scores_list_ff = sorted(funcEnum_2_scores_dict_fg[funcEnum])\n",
    "#     assert len(scores_list_sparse) ==\n",
    "#     len(scores_list_ff)\n",
    "#     assert scores_list_sparse == scores_list_ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scores_list_sparse), len(scores_list_ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcEnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcEnum = 256 # Nucleus\n",
    "sum(funcEnum_2_scores_dict_fg[funcEnum] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foreground_n, background_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ui.foreground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pqo.taxid_2_proteome_count[559292]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfc.groupby(\"etype\")[\"term\"].count())\n",
    "print(dfs.groupby(\"etype\")[\"term\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfc[dfc[\"etype\"] == -20].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[dfs[\"term\"] == \"GOCC:0005634\"].FG_IDs.values[0] == dfc[dfc[\"term\"] == \"GOCC:0005634\"].FG_IDs.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfs[dfs[\"term\"] == \"GOCC:0005634\"].FG_IDs.values[0].split(\";\")), len(dfc[dfc[\"term\"] == \"GOCC:0005634\"].FG_IDs.values[0].split(\";\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[dfs[\"term\"] == \"GOCC:0005634\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc[dfc[\"term\"] == \"GOCC:0005634\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.986195 - 0.950679"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.groupby(\"etype\").term.count(), dfc.groupby(\"etype\").term.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "126/177"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs[dfs[\"etype\"] == -20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfc = df.copy()\n",
    "# dfc.groupby(\"etype\").head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs = df.copy()\n",
    "# dfs.groupby(\"etype\").head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[dfs[\"etype\"] == -20].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc[dfc[\"etype\"] == -20].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yeast acetylation, underrepresented, scipy\n",
    "print(df.shape)\n",
    "print(df.groupby(\"etype\")[\"term\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yeast acetylation, underrepresented, cython\n",
    "print(df.shape)\n",
    "print(df.groupby(\"etype\")[\"term\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yeast acetylation, both, scipy\n",
    "print(df.shape)\n",
    "print(df.groupby(\"etype\")[\"term\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yeast acetylation, both, cython\n",
    "print(df.shape)\n",
    "print(df.groupby(\"etype\")[\"term\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yeast acetylation, overrepresented, cython\n",
    "print(df.shape)\n",
    "print(df.groupby(\"etype\")[\"term\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"etype\"] == -51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"etype\").head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problematic call\n",
    "foreground_input = '511145.b1260%0d511145.b1261%0d511145.b1262%0d511145.b1263%0d511145.b1264%0d511145.b1812%0d511145.b2551%0d511145.b3117%0d511145.b3772%0d511145.b1015%0d511145.b2585'\n",
    "foreground_input = foreground_input.split(\"%0d\")\n",
    "background_input = []\n",
    "\n",
    "enrichment_method = \"genome\"\n",
    "args_dict = {}\n",
    "args_dict[\"enrichment_method\"] = enrichment_method\n",
    "args_dict[\"taxid\"] = 511145\n",
    "args_dict[\"FDR_cutoff\"] = 0.05\n",
    "args_dict[\"p_value_cutoff\"] = 0.01\n",
    "args_dict[\"limit_2_entity_type\"] = None # \"-20;-25;-26\" #\"-21;-22;-23;-51;-52;-53;-54;-55;-56-57;-58\"\n",
    "args_dict[\"filter_PMID_top_n\"] = 100\n",
    "args_dict[\"filter_foreground_count_one\"] = False\n",
    "args_dict[\"filter_parents\"] = False\n",
    "args_dict[\"go_slim_subset\"] = None # \"generic\"\n",
    "args_dict[\"o_or_u_or_both\"] = \"both\" # \"both\" \"underrepresented\" \"overrepresented\"\n",
    "args_dict[\"multiple_testing_per_etype\"] = True\n",
    "args_dict[\"privileged\"] = True\n",
    "args_dict[\"score_cutoff\"] = 0\n",
    "args_dict[\"caller_identity\"] = \"11_0\"\n",
    "taxid = args_dict[\"taxid\"]\n",
    "debug = False\n",
    "profile = False\n",
    "simplified_output = False\n",
    "args_dict[\"simplified_output\"] = simplified_output\n",
    "args_dict[\"STRING_beta\"] = True\n",
    "KS_method = \"cy\"\n",
    "# result = requests.post(url_, params={\"output_format\": \"tsv\", \"enrichment_method\": \"genome\", \"taxid\": 511145, \"caller_identity\": \"11_0\", \"STRING_beta\": True, \n",
    "#                                      'FDR_cutoff': '0.05'}, data={\"foreground\": fg, \"background\": bg})\n",
    "ui = userinput.Userinput(pqo, fn=None, foreground_string=userinput.stringify_for_Userinput(foreground_input), background_string=userinput.stringify_for_Userinput(background_input), args_dict=args_dict)\n",
    "preloaded_objects_per_analysis = pqo.get_preloaded_objects_per_analysis()\n",
    "if debug:\n",
    "    funcEnum_2_scores_dict_bg, foreground_n, background_n, fg_scores_matrix_data, fg_scores_matrix_indptr, bg_scores_matrix_data, bg_scores_matrix_indptr, p_values, cond_multitest, effectSizes, p_value_cutoff, funcEnum_count_foreground, funcEnum_count_background, over_under_int_arr, o_or_u_or_both_encoding, em, filter_foreground_count_one = run_enrichment_cy(ncbi, ui, preloaded_objects_per_analysis, static_preloaded_objects, low_memory=True, debug=debug, KS_method=KS_method, ENSP_2_tuple_funcEnum_score_dict=ENSP_2_tuple_funcEnum_score_dict)\n",
    "else:\n",
    "    df = run_enrichment_cy(ncbi, ui, preloaded_objects_per_analysis, static_preloaded_objects, low_memory=True, debug=debug, KS_method=KS_method, ENSP_2_tuple_funcEnum_score_dict=ENSP_2_tuple_funcEnum_score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"etype\").head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from io import StringIO\n",
    "# import pandas as pd\n",
    "# # call api_help for help and argument defaults\n",
    "# response = requests.get(r\"https://agotool.org/api_help\")\n",
    "# print(response.json())\n",
    "# url_ = r\"https://agotool.org/api\"\n",
    "# # url_ = r\"http://localhost:5000/api\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENSPs = ['4932.YAR019C', '4932.YFR028C', '4932.YGR092W', '4932.YHR152W', '4932.YIL106W', '4932.YJL076W',\n",
    "#      '4932.YLR079W', '4932.YML064C', '4932.YMR055C', '4932.YOR373W', '4932.YPR119W']\n",
    "# fg = \"%0d\".join(ENSPs)\n",
    "# result = requests.post(url_,\n",
    "#                    params={\"output_format\": \"tsv\",\n",
    "#                            \"enrichment_method\": \"genome\",\n",
    "#                            \"taxid\": 559292, \"STRING_beta\": True}, \n",
    "#                        # UniProt reference proteomes uses \"Saccharomyces cerevisiae S288C\" with Taxid 559292 as a pan proteome instead of 4932 (TaxID on taxonomic rank of species).\n",
    "#                    data={\"foreground\": fg})\n",
    "# result = result.text\n",
    "# df = pd.read_csv(StringIO(result), sep='\\t')\n",
    "# df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from io import StringIO\n",
    "# import pandas as pd\n",
    "\n",
    "# url_ = r\"https://agotool.org/api\"\n",
    "# ENSPs = ['4932.YAR019C', '4932.YFR028C', '4932.YGR092W', '4932.YHR152W', '4932.YIL106W', '4932.YJL076W',\n",
    "#      '4932.YLR079W', '4932.YML064C', '4932.YMR055C', '4932.YOR373W', '4932.YPR119W']\n",
    "# fg = \"%0d\".join(ENSPs)\n",
    "# result = requests.post(url_,\n",
    "#                    params={\"output_format\": \"tsv\",\n",
    "#                            \"enrichment_method\": \"genome\",\n",
    "#                            \"taxid\": 559292, \"STRING_beta\": False}, \n",
    "#                        # UniProt reference proteomes uses \"Saccharomyces cerevisiae S288C\" with Taxid 559292 as a pan proteome instead of 4932 (TaxID on taxonomic rank of species).\n",
    "#                    data={\"foreground\": fg})\n",
    "# result = result.text\n",
    "# df = pd.read_csv(StringIO(result), sep='\\t')\n",
    "# df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo PyTests 2 write\n",
    "# compare ENSP_2_tuple_funcEnum_score_dict with Sparse Matrix (funcEnum_2_scores_dict_fg, funcEnum_2_scores_dict_bg). \n",
    "#   For any given input (of taxid 9606) check that FG_count <= BG_count\n",
    "#   funcEnums of FG must also be in BG\n",
    "#   scores of FG must also be in BG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for given Protein what functions are associated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_scores_matrix, list_of_rowIndices_fg = slice_ScoresMatrix_for_given_ENSP(protein_ans_fg, ENSP_2_rowIndex_dict, CSC_ENSPencoding_2_FuncEnum)\n",
    "fg_scores_matrix_data = fg_scores_matrix.data\n",
    "fg_scores_matrix_indptr = fg_scores_matrix.indptr\n",
    "set_fg_counts(fg_scores_matrix_data, fg_scores_matrix_indptr, funcEnum_count_foreground, filter_foreground_count_one)\n",
    "# add_funcEnums_2_dict(protein_ans_fg, ENSP_2_functionEnumArray_dict, ENSP_2_tuple_funcEnum_score_dict)\n",
    "add_funcEnums_2_dict_CSC(protein_ans_fg, ENSP_2_functionEnumArray_dict, ENSP_2_rowIndex_dict, CSR_ENSPencoding_2_FuncEnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How can the FG_count always be as high as FG_n?\n",
    "# Why is BG_count not >= as FG_count? --> PyTest\n",
    "funcEnum_2_scores_dict_bg = Taxid_2_FunctionEnum_2_Scores_dict[9606]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g. GOCC:0043226; 1893 (funcEnum) with 59 BG_count, but 97 FG_count and enrichment_method \"genome\"\n",
    "# --> PYTEST: FG_count should always be <= BG_count\n",
    "# CHECK:\n",
    "# Which files are in the pipeline? \n",
    "    # - Lars download with ENSPs\n",
    "    # - translated to UniProtIDs, scaled values from float to int and backtracked\n",
    "    # - counted per TaxID\n",
    "    \n",
    "# Which ENSPs are associated with GOCC:0043226 in original Lars download? \n",
    "# Which UniProtIDs are associated with GOCC:0043226 in original Lars download?\n",
    "# How many and which"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_scores_matrix, list_of_rowIndices_fg = slice_ScoresMatrix_for_given_ENSP(protein_ans_fg, ENSP_2_rowIndex_dict, CSC_ENSPencoding_2_FuncEnum)\n",
    "fg_scores_matrix_data = fg_scores_matrix.data\n",
    "fg_scores_matrix_indptr = fg_scores_matrix.indptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.df_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_scores_per_term_limit_2_inclusionTerms(protein_ans_fg, ENSP_2_tuple_funcEnum_score_dict, funcEnums_2_include_set, list_2_array=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_noFunc_list, scores_list = [], []\n",
    "funcEnum = 1893\n",
    "protein_ans_fg = ui.get_all_individual_foreground_ANs()\n",
    "for prot in protein_ans_fg:\n",
    "    try:\n",
    "        funcEnum_arr, score_arr = ENSP_2_tuple_funcEnum_score_dict[prot]\n",
    "    except:\n",
    "        prot_noFunc_list.append(prot)\n",
    "        continue\n",
    "    x = np.where(funcEnum_arr == funcEnum)[0]\n",
    "    if x.shape[0] == 0:\n",
    "        print(\"\")\n",
    "        continue\n",
    "    else:\n",
    "        index_ = x[0]\n",
    "    scores_list.append(score_arr[index_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scores_list), len(prot_noFunc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcEnum_arr, score_arr = ENSP_2_tuple_funcEnum_score_dict[\"GPT_HUMAN\"]\n",
    "np.where(funcEnum_arr == funcEnum)\n",
    "# index_ = np.where(funcEnum_arr == funcEnum)[0][0]\n",
    "# print(score_arr[index_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del run_cythonized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import run_cythonized\n",
    "reload(run_cythonized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import cProfile\n",
    "# cProfile.run('run_cythonized.run_genome_cy(taxid, protein_ans, background_n, preloaded_objects_per_analysis, static_preloaded_objects, args_dict, low_memory=False)', sort='time') > prof_temp.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## line profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://stackoverflow.com/questions/28301931/how-to-profile-cython-functions-line-by-line\n",
    "## add this to Jupyter Notebook\n",
    "#%%cython -f --compile-args=-DCYTHON_TRACE=1\n",
    "#import Cython\n",
    "######################################\n",
    "### profiling # Set compiler directives (cf. http://docs.cython.org/src/reference/compilation.html)\n",
    "import line_profiler\n",
    "directive_defaults = Cython.Compiler.Options.get_directive_defaults() ### from Cython.Compiler.Options import directive_defaults # deprecated\n",
    "directive_defaults['linetrace'] = True\n",
    "directive_defaults['binding'] = True\n",
    "######################################\n",
    "\n",
    "## then run this to profile\n",
    "# %load_ext line_profiler\n",
    "import line_profiler\n",
    "\n",
    "fn_userinput = r\"/Users/dblyon/modules/cpr/agotool/data/exampledata/ExampleData_for_testing.txt\"\n",
    "foreground_input = [\"HBA_HUMAN\", \"HBB_HUMAN\", \"HBD_HUMAN\", \"HBE_HUMAN\"]\n",
    "taxid = 9606\n",
    "from_file = False\n",
    "\n",
    "args_dict = {}\n",
    "args_dict[\"enrichment_method\"] = \"genome\"\n",
    "args_dict[\"FDR_cutoff\"] = 0.05\n",
    "args_dict[\"p_value_cutoff\"] = 0.01\n",
    "args_dict[\"limit_2_entity_type\"] = \"-20;-25;-21\" # \"-20;-21;-22;-23;-25;-26\" # None #\"-21;-22;-23\"\n",
    "args_dict[\"filter_PMID_top_n\"] = 50\n",
    "args_dict[\"filter_foreground_count_one\"] = True\n",
    "args_dict[\"filter_parents\"] = True\n",
    "args_dict[\"go_slim_subset\"] = None # \"generic\"\n",
    "args_dict[\"taxid\"] = taxid\n",
    "args_dict[\"o_or_u_or_both\"] = \"both\" # \"both\" \"underrepresented\"\n",
    "args_dict[\"multiple_testing_per_etype\"] = True\n",
    "args_dict[\"privileged\"] = True\n",
    "\n",
    "background_input = query.get_proteins_of_taxid(taxid, read_from_flat_files=True)\n",
    "if from_file:\n",
    "    ui = userinput.Userinput(pqo, fn_userinput, args_dict=args_dict)\n",
    "else:\n",
    "    ui = userinput.Userinput(pqo, fn=None, foreground_string=userinput.stringify_for_Userinput(foreground_input), background_string=userinput.stringify_for_Userinput(background_input), args_dict=args_dict)\n",
    "ncbi = pqo.ncbi\n",
    "\n",
    "preloaded_objects_per_analysis = pqo.get_preloaded_objects_per_analysis()\n",
    "profile = line_profiler.LineProfiler(run_enrichment_cy)\n",
    "profile.runcall(run_enrichment_cy, ncbi, ui, preloaded_objects_per_analysis, static_preloaded_objects, low_memory=True)\n",
    "profile.print_stats()\n",
    "# > 70% of time spent on KS (Hemoglobin foreground, genome background). 76.7 (only categories with scores), 69.8 (all categories) \n",
    "#  --> test KS funtion alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running calc_pvalues_v4\n",
      "Timer unit: 1e-06 s\n",
      "\n",
      "Total time: 2.12591 s\n",
      "File: /Users/dblyon/.ipython/cython/_cython_magic_2fd9ca079481bd97d0ed7422c29f4762.pyx\n",
      "Function: run_enrichment_cy at line 106\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   106                                           def run_enrichment_cy(ncbi, ui, preloaded_objects_per_analysis, static_preloaded_objects, low_memory=False, debug=False, pvalue_version=\"old\"):\n",
      "   107         1          2.0      2.0      0.0      if not low_memory:\n",
      "   108                                                   ENSP_2_functionEnumArray_dict, year_arr, hierlevel_arr, entitytype_arr, functionalterm_arr, indices_arr, description_arr, category_arr, etype_2_minmax_funcEnum, function_enumeration_len, etype_cond_dict, etype_2_num_functions_dict, taxid_2_proteome_count, taxid_2_tuple_funcEnum_index_2_associations_counts, lineage_dict_enum, blacklisted_terms_bool_arr, cond_etypes_with_ontology, cond_etypes_rem_foreground_ids, kegg_taxid_2_acronym_dict, goslimtype_2_cond_dict = static_preloaded_objects\n",
      "   109                                               else:  # missing: ENSP_2_functionEnumArray_dict\n",
      "   110         1          2.0      2.0      0.0          year_arr, hierlevel_arr, entitytype_arr, functionalterm_arr, indices_arr, description_arr, category_arr, etype_2_minmax_funcEnum, function_enumeration_len, etype_cond_dict, etype_2_num_functions_dict, taxid_2_proteome_count, taxid_2_tuple_funcEnum_index_2_associations_counts, lineage_dict_enum, blacklisted_terms_bool_arr, cond_etypes_with_ontology, cond_etypes_rem_foreground_ids, kegg_taxid_2_acronym_dict, goslimtype_2_cond_dict = static_preloaded_objects\n",
      "   111         1          2.0      2.0      0.0      foreground_ids_arr_of_string, background_ids_arr_of_string, funcEnum_count_foreground, funcEnum_count_background, p_values, p_values_corrected, cond_multitest, blacklisted_terms_bool_arr_temp, cond_terms_reduced_with_ontology, cond_filter, cond_PMIDs, effectSizes, over_under_int_arr, over_under_arr_of_string = preloaded_objects_per_analysis\n",
      "   112         1         17.0     17.0      0.0      em = ui.enrichment_method\n",
      "   113         1         16.0     16.0      0.0      foreground_n = ui.get_foreground_n()\n",
      "   114         1          1.0      1.0      0.0      args_dict = ui.args_dict\n",
      "   115         1          7.0      7.0      0.0      background_n = ui.get_background_n()\n",
      "   116         1        540.0    540.0      0.0      protein_ans_fg = ui.get_foreground_an_set()\n",
      "   117         1          2.0      2.0      0.0      taxid = args_dict[\"taxid\"]\n",
      "   118         1          1.0      1.0      0.0      filter_foreground_count_one = args_dict[\"filter_foreground_count_one\"]\n",
      "   119         1          1.0      1.0      0.0      p_value_cutoff = args_dict[\"p_value_cutoff\"]\n",
      "   120                                           \n",
      "   121         1          2.0      2.0      0.0      if ui.enrichment_method in {\"abundance_correction\", \"compare_samples\"}: # , \"compare_groups\"\n",
      "   122                                                   protein_ans_bg = ui.get_background_an_set()\n",
      "   123         1          1.0      1.0      0.0      if low_memory:\n",
      "   124         1     146669.0 146669.0      6.9          ENSP_2_functionEnumArray_dict = query.get_functionEnumArray_from_proteins(ui.get_all_individual_AN(), dict_2_array=True)\n",
      "   125                                               ### add protein groups to ENSP_2_functionEnumArray_dict\n",
      "   126         1        439.0    439.0      0.0      ENSP_2_functionEnumArray_dict = add_protein_groups_to_ENSP_2_functionEnumArray_dict(ENSP_2_functionEnumArray_dict, ui.get_all_unique_proteinGroups())\n",
      "   127                                           \n",
      "   128         1      58327.0  58327.0      2.7      count_all_terms(ENSP_2_functionEnumArray_dict, protein_ans_fg, funcEnum_count_foreground)\n",
      "   129                                           \n",
      "   130                                               ### count background\n",
      "   131         1          1.0      1.0      0.0      if em == \"genome\":\n",
      "   132         1          2.0      2.0      0.0          funcEnum_index_2_associations = taxid_2_tuple_funcEnum_index_2_associations_counts[taxid]\n",
      "   133         1          1.0      1.0      0.0          funcEnum_index_positions_arr, counts_arr = funcEnum_index_2_associations\n",
      "   134         1     450318.0 450318.0     21.2          create_funcEnum_count_background_v3(funcEnum_count_background, funcEnum_index_positions_arr, counts_arr)\n",
      "   135                                               elif em == \"abundance_correction\":\n",
      "   136                                                   funcEnum_count_background = count_all_term_abundance_corrected(ui, ENSP_2_functionEnumArray_dict, funcEnum_count_background)\n",
      "   137                                                   background_n = foreground_n\n",
      "   138                                               elif em == \"compare_samples\":\n",
      "   139                                                   count_all_terms(ENSP_2_functionEnumArray_dict, protein_ans_bg, funcEnum_count_background)\n",
      "   140                                               else:\n",
      "   141                                                   args_dict[\"ERROR enrichment_method\"] = \"The 'enrichment_method' you've provided: '{}' doesn't exist / isn't implemented.\".format(args_dict[\"enrichment_method\"])\n",
      "   142                                                   return args_dict\n",
      "   143                                           \n",
      "   144                                               ## limit to given entity types\n",
      "   145         1       1482.0   1482.0      0.1      cond_limit_2_entity_type = limit_to_entity_types(args_dict[\"limit_2_entity_type\"], function_enumeration_len, etype_cond_dict, funcEnum_count_foreground)\n",
      "   146         1          9.0      9.0      0.0      limit_to_go_subset(etype_cond_dict, args_dict[\"go_slim_subset\"], goslimtype_2_cond_dict, funcEnum_count_foreground)\n",
      "   147         1          1.0      1.0      0.0      o_or_u_or_both_encoding = args_dict[\"o_or_u_or_both_encoding\"]\n",
      "   148                                           \n",
      "   149                                               ### calculate Fisher p-values and get bool array for multiple testing\n",
      "   150         1          1.0      1.0      0.0      if pvalue_version == \"old\":\n",
      "   151                                                   print(\"running calc_pvalues\")\n",
      "   152                                                   calc_pvalues(funcEnum_count_foreground, funcEnum_count_background, foreground_n, background_n, p_values, cond_multitest, effectSizes, over_under_int_arr, o_or_u_or_both_encoding)\n",
      "   153         1          1.0      1.0      0.0      elif pvalue_version == \"debug\":\n",
      "   154                                                   return funcEnum_count_foreground, funcEnum_count_background, foreground_n, background_n, p_values, cond_multitest, effectSizes, over_under_int_arr, o_or_u_or_both_encoding\n",
      "   155                                               else:        \n",
      "   156         1        147.0    147.0      0.0          print(\"running calc_pvalues_v4\")\n",
      "   157         1     559851.0 559851.0     26.3          calc_pvalues_v4(funcEnum_count_foreground, funcEnum_count_background, foreground_n, background_n, p_values, cond_multitest, effectSizes, over_under_int_arr, o_or_u_or_both_encoding)\n",
      "   158                                           \n",
      "   159                                               ######################################################################################################################################################\n",
      "   160                                               ### Jensenlab Scores KS test\n",
      "   161                                           #     cond_KS_etypes = etype_cond_dict[\"cond_25\"] | etype_cond_dict[\"cond_26\"] | etype_cond_dict[\"cond_20\"]\n",
      "   162                                           \n",
      "   163                                           #     fg_scores_matrix, list_of_rowIndices_fg = slice_ScoresMatrix_for_given_ENSP(protein_ans_fg, ENSP_2_rowIndex_dict, CSC_ENSPencoding_2_FuncEnum)\n",
      "   164                                           #     fg_scores_matrix_data = fg_scores_matrix.data\n",
      "   165                                           #     fg_scores_matrix_indptr = fg_scores_matrix.indptr\n",
      "   166                                           #     if fg_scores_matrix_data.size > 0:\n",
      "   167                                           #         if em == \"genome\": # \"genome\" has 2 possible KS methods KolmogorovSmirnov_sparse_cy (if fg not a proper subset of bg but comparing to precomputed bg) and KolmogorovSmirnov_sparse_cy_genome.\n",
      "   168                                           #             if KS_method in {\"cy\", \"sparse_scipy\"}:\n",
      "   169                                           #                 bg_scores_matrix_data = None\n",
      "   170                                           #                 bg_scores_matrix_indptr = None\n",
      "   171                                           #                 try:\n",
      "   172                                           #                     funcEnum_2_scores_dict_bg = Taxid_2_FunctionEnum_2_Scores_dict[taxid] # taxid is an Integer\n",
      "   173                                           #                 except KeyError: # no text mining information for this taxon, try to translate to species level and try again. e.g. user provides 559292 (Saccharomyces cerevisiae S288C, UniProt Reference Proteome), but Jensenlab Textmining supports 4932 (Saccharomyces cerevisiae, rank species)\n",
      "   174                                           #                     funcEnum_2_scores_dict_bg = {} # TaxID check is already done in runserver.py and userinput.py\n",
      "   175                                           #                 if KS_method == \"sparse_scipy\":\n",
      "   176                                           #                     KolmogorovSmirnov_sparse_scipy(funcEnum_2_scores_dict_bg, foreground_n, background_n, fg_scores_matrix_data, fg_scores_matrix_indptr, bg_scores_matrix_data, bg_scores_matrix_indptr, p_values, cond_multitest, effectSizes, p_value_cutoff, funcEnum_count_foreground, funcEnum_count_background, over_under_int_arr, o_or_u_or_both_encoding, em, filter_foreground_count_one)\n",
      "   177                                           #                 elif KS_method == \"cy\":\n",
      "   178                                           #                     KolmogorovSmirnov_sparse_cy(funcEnum_2_scores_dict_bg, foreground_n, background_n, fg_scores_matrix_data, fg_scores_matrix_indptr, bg_scores_matrix_data, bg_scores_matrix_indptr, p_values, cond_multitest, effectSizes, p_value_cutoff, funcEnum_count_foreground, funcEnum_count_background, over_under_int_arr, o_or_u_or_both_encoding, em, filter_foreground_count_one)\n",
      "   179                                           #                 else:\n",
      "   180                                           #                     print(\"KS_method {} unknown\".format(KS_method))\n",
      "   181                                           #                     return None\n",
      "   182                                           \n",
      "   183                                           #             elif KS_method == \"scipy\":\n",
      "   184                                           #                 funcEnums_2_include_set = set(indices_arr[cond_KS_etypes & cond_limit_2_entity_type])\n",
      "   185                                           #                 funcEnum_2_scores_dict_fg = collect_scores_per_term_limit_2_inclusionTerms(protein_ans_fg, ENSP_2_tuple_funcEnum_score_dict, funcEnums_2_include_set, list_2_array=True)\n",
      "   186                                           #                 funcEnum_2_scores_dict_bg = Taxid_2_FunctionEnum_2_Scores_dict[taxid]\n",
      "   187                                           #                 if debug:\n",
      "   188                                           #                     return foreground_n, background_n, funcEnum_2_scores_dict_fg, funcEnum_2_scores_dict_bg, p_values, cond_multitest, effectSizes, p_value_cutoff, funcEnum_count_foreground, funcEnum_count_background, over_under_int_arr, o_or_u_or_both_encoding, True\n",
      "   189                                           #                 print(\"running KolmogorovSmirnov_scipy\")\n",
      "   190                                           #                 KolmogorovSmirnov_scipy(foreground_n, background_n, funcEnum_2_scores_dict_fg, funcEnum_2_scores_dict_bg, p_values, cond_multitest, effectSizes, p_value_cutoff, funcEnum_count_foreground, funcEnum_count_background, over_under_int_arr, o_or_u_or_both_encoding, fill_zeros=True)\n",
      "   191                                           #             else:\n",
      "   192                                           #                 print(\"KS_method {} not implemented\".format(KS_method))\n",
      "   193                                           #                 return None\n",
      "   194                                           #         elif em in {\"compare_samples\", \"abundance_correction\"}: # abundance_correction calculated the same way as compare_samples, background_n will differ from non-KS etypes\n",
      "   195                                           #             if KS_method in {\"cy\", \"sparse_scipy\"}:\n",
      "   196                                           #                 bg_scores_matrix, list_of_rowIndices_bg = slice_ScoresMatrix_for_given_ENSP(protein_ans_bg, ENSP_2_rowIndex_dict, CSC_ENSPencoding_2_FuncEnum)\n",
      "   197                                           #                 bg_scores_matrix_data = bg_scores_matrix.data\n",
      "   198                                           #                 bg_scores_matrix_indptr = bg_scores_matrix.indptr\n",
      "   199                                           #                 funcEnum_2_scores_dict_bg = None\n",
      "   200                                           #                 if em == \"abundance_correction\":\n",
      "   201                                           #                     background_n_temp = ui.background.shape[0]\n",
      "   202                                           #                 else:\n",
      "   203                                           #                     background_n_temp = background_n\n",
      "   204                                           #                 if debug:\n",
      "   205                                           #                     return funcEnum_2_scores_dict_bg, foreground_n, background_n_temp, fg_scores_matrix_data, fg_scores_matrix_indptr, bg_scores_matrix_data, bg_scores_matrix_indptr, p_values, cond_multitest, effectSizes, p_value_cutoff, funcEnum_count_foreground, funcEnum_count_background, over_under_int_arr, o_or_u_or_both_encoding, em, filter_foreground_count_one\n",
      "   206                                           #                 if KS_method == \"cy\":\n",
      "   207                                           #                     print(\"running KolmogorovSmirnov_sparse_cy\")\n",
      "   208                                           #                     KolmogorovSmirnov_sparse_cy(funcEnum_2_scores_dict_bg, foreground_n, background_n_temp, fg_scores_matrix_data, fg_scores_matrix_indptr, bg_scores_matrix_data, bg_scores_matrix_indptr, p_values, cond_multitest, effectSizes, p_value_cutoff, funcEnum_count_foreground, funcEnum_count_background, over_under_int_arr, o_or_u_or_both_encoding, em, filter_foreground_count_one)\n",
      "   209                                           #                 elif KS_method == \"sparse_scipy\":\n",
      "   210                                           #                     print(\"running KolmogorovSmirnov_sparse_scipy\")\n",
      "   211                                           #                     KolmogorovSmirnov_sparse_scipy(funcEnum_2_scores_dict_bg, foreground_n, background_n_temp, fg_scores_matrix_data, fg_scores_matrix_indptr, bg_scores_matrix_data, bg_scores_matrix_indptr, p_values, cond_multitest, effectSizes, p_value_cutoff, funcEnum_count_foreground, funcEnum_count_background, over_under_int_arr, o_or_u_or_both_encoding, em, filter_foreground_count_one)\n",
      "   212                                           #                 else:\n",
      "   213                                           #                     print(\"KS_method {} unknown\".format(KS_method))\n",
      "   214                                           #                     return None\n",
      "   215                                           #             elif KS_method == \"scipy\":\n",
      "   216                                           #                 funcEnums_2_include_set = set(indices_arr[cond_KS_etypes & cond_limit_2_entity_type])\n",
      "   217                                           #                 funcEnum_2_scores_dict_fg = collect_scores_per_term_limit_2_inclusionTerms(protein_ans_fg, ENSP_2_tuple_funcEnum_score_dict, funcEnums_2_include_set, list_2_array=True)\n",
      "   218                                           #                 funcEnum_2_scores_dict_bg = collect_scores_per_term_limit_2_inclusionTerms(protein_ans_bg, ENSP_2_tuple_funcEnum_score_dict, funcEnums_2_include_set, list_2_array=True)\n",
      "   219                                           #                 print(\"running KolmogorovSmirnov_scipy\")\n",
      "   220                                           #                 if debug:\n",
      "   221                                           #                     fill_zeros = True\n",
      "   222                                           #                     return foreground_n, background_n, funcEnum_2_scores_dict_fg, funcEnum_2_scores_dict_bg, p_values, cond_multitest, effectSizes, p_value_cutoff, funcEnum_count_foreground, funcEnum_count_background, over_under_int_arr, o_or_u_or_both_encoding, fill_zeros\n",
      "   223                                           #                 KolmogorovSmirnov_scipy(foreground_n, background_n, funcEnum_2_scores_dict_fg, funcEnum_2_scores_dict_bg, p_values, cond_multitest, effectSizes, p_value_cutoff, funcEnum_count_foreground, funcEnum_count_background, over_under_int_arr, o_or_u_or_both_encoding, fill_zeros=True)\n",
      "   224                                           \n",
      "   225                                               #### other methods e.g. abundance_correction, compare_samples are missing  #!!!\n",
      "   226                                               ### don't delete \"add_funcEnums_2_dict_CSC\", not using due to speed and too many proteins in list --> but use for characterize_foreground\n",
      "   227                                               # add_funcEnums_2_dict_CSC(protein_ans_fg, ENSP_2_functionEnumArray_dict, ENSP_2_rowIndex_dict, CSR_ENSPencoding_2_FuncEnum)\n",
      "   228                                           \n",
      "   229                                               ### \"over/under\"\n",
      "   230         1          1.0      1.0      0.0      if o_or_u_or_both_encoding == 1: # overrepresented\n",
      "   231                                                   over_under_arr_of_string[over_under_int_arr == 1] = \"o\"\n",
      "   232         1          1.0      1.0      0.0      elif o_or_u_or_both_encoding == 0: # both\n",
      "   233         1      10893.0  10893.0      0.5          over_under_arr_of_string[over_under_int_arr == 1] = \"o\"\n",
      "   234         1       2125.0   2125.0      0.1          over_under_arr_of_string[over_under_int_arr == 2] = \"u\"\n",
      "   235                                               elif o_or_u_or_both_encoding == 2: # underrepresented\n",
      "   236                                                   over_under_arr_of_string[over_under_int_arr == 2] = \"u\"\n",
      "   237                                               else: # check already done above\n",
      "   238                                                   return args_dict\n",
      "   239                                               ### multiple testing per entity type, save results preformed p_values_corrected\n",
      "   240         1          2.0      2.0      0.0      if args_dict[\"multiple_testing_per_etype\"]:\n",
      "   241         1          3.0      3.0      0.0          for etype_name, cond_etype in etype_cond_dict.items():\n",
      "   242        13         37.0      2.8      0.0              num_total_tests = etype_2_num_functions_dict[etype_name]\n",
      "   243        13      51403.0   3954.1      2.4              multiple_testing_per_entity_type(cond_etype, cond_multitest, p_values, p_values_corrected, indices_arr, num_total_tests)\n",
      "   244                                               else:\n",
      "   245                                                   cond_all = np.ones(function_enumeration_len, dtype=bool)\n",
      "   246                                                   num_total_tests = cond_all.shape[0]\n",
      "   247                                                   multiple_testing_per_entity_type(cond_all, cond_multitest, p_values, p_values_corrected, indices_arr, num_total_tests)\n",
      "   248                                           \n",
      "   249                                               ### Filter stuff\n",
      "   250                                           #     if KS_etypes_FG_IDs:\n",
      "   251                                           #         add_funcEnums_2_dict_CSC(protein_ans_fg, ENSP_2_functionEnumArray_dict, ENSP_2_rowIndex_dict, CSR_ENSPencoding_2_FuncEnum)\n",
      "   252         1     139460.0 139460.0      6.6      foreground_ids_arr_of_string, funcEnum_indices_for_IDs, cond_etypes_with_ontology_filtered, cond_etypes_rem_foreground_ids_filtered, cond_filter = filter_stuff(args_dict, protein_ans_fg, p_values_corrected, foreground_ids_arr_of_string, funcEnum_count_foreground, year_arr, p_values, indices_arr, ENSP_2_functionEnumArray_dict, cond_filter, etype_cond_dict, cond_PMIDs, cond_etypes_with_ontology, cond_etypes_rem_foreground_ids, over_under_int_arr)\n",
      "   253         1          2.0      2.0      0.0      if debug:\n",
      "   254                                                   return foreground_ids_arr_of_string\n",
      "   255         1          0.0      0.0      0.0      if em in {\"compare_samples\"}:\n",
      "   256                                                   background_ids_arr_of_string = map_funcEnum_2_ENSPs(protein_ans_bg, ENSP_2_functionEnumArray_dict, funcEnum_indices_for_IDs, background_ids_arr_of_string)\n",
      "   257                                           \n",
      "   258                                               ### filter etypes with ontologies --> cond_terms_reduced_with_ontology\n",
      "   259         1       7137.0   7137.0      0.3      df_with_ontology = pd.DataFrame({\"term_enum\": indices_arr[cond_etypes_with_ontology_filtered].view(), \"foreground_ids\": foreground_ids_arr_of_string[cond_etypes_with_ontology_filtered].view(), \"hierarchical_level\": hierlevel_arr[cond_etypes_with_ontology_filtered].view(), \"p_value\": p_values[cond_etypes_with_ontology_filtered].view(), \"foreground_count\": funcEnum_count_foreground[cond_etypes_with_ontology_filtered].view(), \"etype\": entitytype_arr[cond_etypes_with_ontology_filtered].view()})\n",
      "   260         1          2.0      2.0      0.0      if args_dict[\"filter_parents\"]: # only for etypes with ontology, but since foreground IDs needed get them for all\n",
      "   261         1     163719.0 163719.0      7.7          filter_parents_if_same_foreground(blacklisted_terms_bool_arr_temp, cond_terms_reduced_with_ontology, lineage_dict_enum, df_with_ontology) # modifies cond_terms_reduced_with_ontology inplace\n",
      "   262                                               else: # since no filtering done use all etypes with ontology\n",
      "   263                                                   cond_terms_reduced_with_ontology = cond_filter & cond_etypes_with_ontology\n",
      "   264                                               ### concatenate filtered results\n",
      "   265         1       2694.0   2694.0      0.1      cond_2_return = cond_PMIDs | cond_terms_reduced_with_ontology | cond_etypes_rem_foreground_ids_filtered\n",
      "   266                                           \n",
      "   267                                               # df_2_return = pd.DataFrame({\"term\": functionalterm_arr[cond_2_return].view(),\n",
      "   268                                               #                         \"hierarchical_level\": hierlevel_arr[cond_2_return].view(),\n",
      "   269                                               #                         \"p_value\": p_values[cond_2_return].view(),\n",
      "   270                                               #                         \"FDR\": p_values_corrected[cond_2_return].view(),\n",
      "   271                                               #                         \"category\": category_arr[cond_2_return].view(),\n",
      "   272                                               #                         \"etype\": entitytype_arr[cond_2_return].view(),\n",
      "   273                                               #                         \"description\": description_arr[cond_2_return].view(),\n",
      "   274                                               #                         \"year\": year_arr[cond_2_return].view(),\n",
      "   275                                               #                         \"FG_IDs\": foreground_ids_arr_of_string[cond_2_return].view(),\n",
      "   276                                               #                         \"FG_count\": funcEnum_count_foreground[cond_2_return].view(),\n",
      "   277                                               #                         \"BG_count\": funcEnum_count_background[cond_2_return].view(),\n",
      "   278                                               #                         \"effectSize\": effectSizes[cond_2_return].view(),\n",
      "   279                                               #                         \"over_under\": over_under_arr_of_string[cond_2_return].view(),\n",
      "   280                                               #                         \"funcEnum\": indices_arr[cond_2_return].view()})\n",
      "   281         1        817.0    817.0      0.0      df_2_return = pd.DataFrame({cn.term: functionalterm_arr[cond_2_return].view(),\n",
      "   282         1        707.0    707.0      0.0                              cn.hierarchical_level: hierlevel_arr[cond_2_return].view(),\n",
      "   283         1        698.0    698.0      0.0                              cn.p_value: p_values[cond_2_return].view(),\n",
      "   284         1        551.0    551.0      0.0                              cn.FDR: p_values_corrected[cond_2_return].view(),\n",
      "   285         1        575.0    575.0      0.0                              cn.category: category_arr[cond_2_return].view(),\n",
      "   286         1        585.0    585.0      0.0                              cn.etype: entitytype_arr[cond_2_return].view(),\n",
      "   287         1        828.0    828.0      0.0                              cn.description: description_arr[cond_2_return].view(),\n",
      "   288         1        703.0    703.0      0.0                              cn.year: year_arr[cond_2_return].view(),\n",
      "   289         1        733.0    733.0      0.0                              cn.FG_IDs: foreground_ids_arr_of_string[cond_2_return].view(),\n",
      "   290         1        544.0    544.0      0.0                              cn.FG_count: funcEnum_count_foreground[cond_2_return].view(),\n",
      "   291         1        531.0    531.0      0.0                              cn.BG_count: funcEnum_count_background[cond_2_return].view(),\n",
      "   292         1        670.0    670.0      0.0                              cn.effect_size: effectSizes[cond_2_return].view(),\n",
      "   293         1        700.0    700.0      0.0                              cn.over_under: over_under_arr_of_string[cond_2_return].view(),\n",
      "   294         1       3344.0   3344.0      0.2                              cn.funcEnum: indices_arr[cond_2_return].view()})\n",
      "   295                                           \n",
      "   296         1          4.0      4.0      0.0      cols_2_return_sort_order = cn.cols_2_return_run_enrichment_cy[:]\n",
      "   297         1          1.0      1.0      0.0      if em in {\"compare_samples\"}:\n",
      "   298                                                   df_2_return[cn.BG_IDs] = background_ids_arr_of_string[cond_2_return].view()\n",
      "   299                                               else:\n",
      "   300         1          2.0      2.0      0.0          cols_2_return_sort_order.remove(cn.BG_IDs)\n",
      "   301         1       4932.0   4932.0      0.2      df_2_return[\"s_value\"] = get_s_value(df_2_return)\n",
      "   302                                               # df_2_return[\"s_value_abs\"] = df_2_return[\"s_value\"].apply(lambda x: abs(x))\n",
      "   303         1        798.0    798.0      0.0      df_2_return[\"s_value_abs\"] = np.abs(df_2_return[\"s_value\"])\n",
      "   304         1       4548.0   4548.0      0.2      df_2_return = df_2_return.sort_values([cn.etype, \"s_value_abs\", cn.hierarchical_level, cn.year], ascending=[False, False, False, False]).reset_index(drop=True)\n",
      "   305         1       2414.0   2414.0      0.1      df_2_return[cn.rank] = df_2_return.groupby(cn.etype)[\"s_value_abs\"].rank(ascending=False, method=\"first\").fillna(value=df_2_return.shape[0]).astype(int)\n",
      "   306         1          1.0      1.0      0.0      if debug:\n",
      "   307                                                       return protein_ans_bg, ENSP_2_functionEnumArray_dict, funcEnum_indices_for_IDs, background_ids_arr_of_string, df_2_return\n",
      "   308         1     497729.0 497729.0     23.4      df_2_return = ui.translate_primary_back_to_secondary(df_2_return)\n",
      "   309         1        910.0    910.0      0.0      df_2_return[cn.FG_n] = foreground_n\n",
      "   310         1        611.0    611.0      0.0      df_2_return[cn.BG_n] = background_n\n",
      "   311                                           \n",
      "   312                                               ### calc ratio in foreground, count foreground / len(protein_ans)\n",
      "   313         1       1018.0   1018.0      0.0      df_2_return[cn.ratio_in_FG] = df_2_return[cn.FG_count] / df_2_return[cn.FG_n]\n",
      "   314         1       1034.0   1034.0      0.0      df_2_return[cn.ratio_in_BG] = df_2_return[cn.BG_count] / df_2_return[cn.BG_n]\n",
      "   315         1          3.0      3.0      0.0      if args_dict[\"STRING_beta\"]:\n",
      "   316                                                   # df_2_return = df_2_return.rename(columns={\"BG_count\": 'background_count', \"FG_count\": 'foreground_count', \"FG_IDs\": 'foreground_ids'})\n",
      "   317                                                   # return df_2_return[variables.cols_sort_order_STRING_API]\n",
      "   318                                                   return df_2_return[cn.cols_sort_order_STRING_API].rename(columns=cn.colnames_2_rename_dict_STRING)\n",
      "   319         1       4600.0   4600.0      0.2      return df_2_return[cols_2_return_sort_order]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### testing calc_pvalues_new vs old\n",
    "#%%cython -f --compile-args=-DCYTHON_TRACE=1\n",
    "#import Cython\n",
    "######################################\n",
    "### profiling # Set compiler directives (cf. http://docs.cython.org/src/reference/compilation.html)\n",
    "import line_profiler\n",
    "directive_defaults = Cython.Compiler.Options.get_directive_defaults() ### from Cython.Compiler.Options import directive_defaults # deprecated\n",
    "directive_defaults['linetrace'] = True\n",
    "directive_defaults['binding'] = True\n",
    "######################################\n",
    "\n",
    "## then run this to profile\n",
    "# %load_ext line_profiler\n",
    "import line_profiler\n",
    "\n",
    "fn_userinput = r\"/Users/dblyon/modules/cpr/agotool/data/exampledata/ExampleData_for_testing.txt\"\n",
    "# foreground_input = [\"HBA_HUMAN\", \"HBB_HUMAN\", \"HBD_HUMAN\", \"HBE_HUMAN\"]\n",
    "taxid = 9606\n",
    "from_file = True\n",
    "contiguous = True\n",
    "foreground_n = 500\n",
    "# foreground_input = sorted(get_random_human_ENSP(foreground_n, joined_for_web=False, contiguous=contiguous, UniProt_ID=True))\n",
    "\n",
    "args_dict = {}\n",
    "args_dict[\"enrichment_method\"] = \"genome\"\n",
    "args_dict[\"FDR_cutoff\"] = 0.05\n",
    "args_dict[\"p_value_cutoff\"] = 0.01\n",
    "args_dict[\"limit_2_entity_type\"] = None # \"-20;-25;-21\" # \"-20;-21;-22;-23;-25;-26\" # None #\"-21;-22;-23\"\n",
    "args_dict[\"filter_PMID_top_n\"] = 50\n",
    "args_dict[\"filter_foreground_count_one\"] = True\n",
    "args_dict[\"filter_parents\"] = True\n",
    "args_dict[\"go_slim_subset\"] = None # \"generic\"\n",
    "args_dict[\"taxid\"] = taxid\n",
    "args_dict[\"o_or_u_or_both\"] = \"both\" # \"both\" \"underrepresented\"\n",
    "args_dict[\"multiple_testing_per_etype\"] = True\n",
    "args_dict[\"privileged\"] = True\n",
    "\n",
    "background_input = query.get_proteins_of_taxid(taxid, read_from_flat_files=True)\n",
    "if from_file:\n",
    "    ui = userinput.Userinput(pqo, fn_userinput, args_dict=args_dict)\n",
    "else:\n",
    "    ui = userinput.Userinput(pqo, fn=None, foreground_string=userinput.stringify_for_Userinput(foreground_input), background_string=userinput.stringify_for_Userinput(background_input), args_dict=args_dict)\n",
    "ncbi = pqo.ncbi\n",
    "\n",
    "preloaded_objects_per_analysis = pqo.get_preloaded_objects_per_analysis()\n",
    "profile = line_profiler.LineProfiler(run_enrichment_cy)\n",
    "profile.runcall(run_enrichment_cy, ncbi, ui, preloaded_objects_per_analysis, static_preloaded_objects, low_memory=True, pvalue_version=\"new\")\n",
    "profile.print_stats()\n",
    "# > 70% of time spent on KS (Hemoglobin foreground, genome background). 76.7 (only categories with scores), 69.8 (all categories) \n",
    "#  --> test KS funtion alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get objects for code block below\n",
    "foreground_input = [\"HBA_HUMAN\", \"HBB_HUMAN\", \"HBD_HUMAN\", \"HBE_HUMAN\"] # example 1: Human hemoglobin, genome\n",
    "enrichment_method = \"genome\" # \"characterize_foreground\" \"abundance_correction\" \"compare_samples\" \"genome\" \"compare_groups\"\n",
    "from_file = False\n",
    "args_dict = {}\n",
    "args_dict[\"enrichment_method\"] = enrichment_method\n",
    "args_dict[\"taxid\"] = 9606\n",
    "args_dict[\"FDR_cutoff\"] = 0.05\n",
    "args_dict[\"p_value_cutoff\"] = 0.01\n",
    "args_dict[\"limit_2_entity_type\"] = \"-20;-25;-26\" #\"-20;-25;-21\" # \"-20;-21;-22;-23;-25;-26\" # None #\"-21;-22;-23\"\n",
    "args_dict[\"filter_PMID_top_n\"] = 50\n",
    "args_dict[\"filter_foreground_count_one\"] = True\n",
    "args_dict[\"filter_parents\"] = True\n",
    "args_dict[\"go_slim_subset\"] = None # \"generic\"\n",
    "args_dict[\"o_or_u_or_both\"] = \"overrepresented\" # \"both\" \"underrepresented\"\n",
    "args_dict[\"multiple_testing_per_etype\"] = True\n",
    "args_dict[\"privileged\"] = True\n",
    "args_dict[\"score_cutoff\"] = 0\n",
    "args_dict[\"foreground_replicates\"] = 10\n",
    "args_dict[\"background_replicates\"] = 10\n",
    "taxid = args_dict[\"taxid\"]\n",
    "background_input = query.get_proteins_of_taxid(taxid, read_from_flat_files=True)\n",
    "if from_file:\n",
    "    ui = userinput.Userinput(pqo, fn_userinput, args_dict=args_dict)\n",
    "else:\n",
    "    ui = userinput.Userinput(pqo, fn=None, foreground_string=userinput.stringify_for_Userinput(foreground_input), background_string=userinput.stringify_for_Userinput(background_input), args_dict=args_dict)\n",
    "ncbi = pqo.ncbi\n",
    "preloaded_objects_per_analysis = pqo.get_preloaded_objects_per_analysis()\n",
    "foreground_n, background_n, funcEnum_2_scores_dict_fg, funcEnum_2_scores_dict_bg, p_values, cond_multitest, effectSizes, p_value_cutoff, funcEnum_count_foreground, funcEnum_count_background, over_under_int_arr, o_or_u_or_both_encoding = run_enrichment_cy(ncbi, ui, preloaded_objects_per_analysis, static_preloaded_objects, low_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import distributions\n",
    "def ks_2samp_dbl(data1, data2):\n",
    "    data1 = np.sort(data1)\n",
    "    data2 = np.sort(data2)\n",
    "    data1 = np.array(data1)\n",
    "    data2 = np.array(data2)\n",
    "    n1 = data1.shape[0]\n",
    "    n2 = data2.shape[0]\n",
    "    data_all = np.concatenate([data1, data2])\n",
    "    cdf1 = np.searchsorted(data1, data_all, side='right') / n1\n",
    "    cdf2 = np.searchsorted(data2, data_all, side='right') / n2\n",
    "    d = np.max(np.absolute(cdf1 - cdf2))\n",
    "    # Note: d absolute not signed distance\n",
    "    en = np.sqrt(n1 * n2 / (n1 + n2))\n",
    "    try:\n",
    "        prob = distributions.kstwobign.sf((en + 0.12 + 0.11 / en) * d)\n",
    "    # except Exception:\n",
    "        # warnings.warn('This should not happen! Please open an issue at '\n",
    "        #             'https://github.com/scipy/scipy/issues and provide the code '\n",
    "        #            'you used to trigger this warning.\\n')\n",
    "        # prob = 1.0\n",
    "    except:\n",
    "        print(\"This shouldn't happen\")\n",
    "        raise StopIteration\n",
    "\n",
    "    # return Ks_2sampResult(d, prob)\n",
    "    return d, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### fill with zeros for proper calculation and performance evaluation\n",
    "funcEnum = 68613\n",
    "scores_fg = funcEnum_2_scores_dict_fg[funcEnum]\n",
    "scores_bg = funcEnum_2_scores_dict_bg[funcEnum]\n",
    "scores_bg = list(scores_bg) # for genome method --> not the place to do this        \n",
    "len_scores_fg = len(scores_fg)\n",
    "number_of_zeros_2_fill = foreground_n - len_scores_fg\n",
    "if number_of_zeros_2_fill > 0:\n",
    "    scores_fg = [0]*number_of_zeros_2_fill + scores_fg\n",
    "len_scores_bg = len(scores_bg)\n",
    "number_of_zeros_2_fill = background_n - len_scores_bg\n",
    "if number_of_zeros_2_fill > 0:\n",
    "    scores_bg = [0]*number_of_zeros_2_fill + scores_bg    \n",
    "data1, data2 = scores_fg, scores_bg\n",
    "\n",
    "d_dbl, prob_dbl = ks_2samp_dbl(data1, data2)\n",
    "d, prob = stats.ks_2samp(data1, data2, alternative=\"two-sided\", mode=\"asymp\")\n",
    "print(d_dbl, prob_dbl)\n",
    "assert d_dbl == d\n",
    "# assert prob_dbl == prob\n",
    "prob_dbl == prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of_floats_2_R_style(vals, max_num_vals_per_line=100):\n",
    "    vals = [str(ele) for ele in vals]\n",
    "    string_2_return = \"<-c(\"\n",
    "    while len(vals) > 0:\n",
    "        string_2_return += \"{},\\n\".format(\", \".join(vals[:max_num_vals_per_line]))\n",
    "        vals = vals[max_num_vals_per_line:]\n",
    "    return string_2_return[:-2] + \")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformation_to_randomize_sort_order(fg, bg):\n",
    "    # value = value * ((double) 1.0 + ((double) rand()) / (((double) RAND_MAX) * (double) 1000.0)); // transformation of fold_change values in order to randomize sort order in case of ties\n",
    "    np.random.seed(12345)\n",
    "#     fg = [value * (1.0 + np.random.randint(0, 2147483647) / (2147483647.0 * 1000.0)) for value in fg]\n",
    "    # bg = [value * (1.0 + np.random.randint(0, 2147483647) / (2147483647.0 * 1000.0)) for value in bg]\n",
    "    fg = [value + np.random.randint(0, 2147483647) / (2147483647.0 * 1000.0) for value in fg]\n",
    "    bg = [value + np.random.randint(0, 2147483647) / (2147483647.0 * 1000.0) for value in bg]\n",
    "    return fg, bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcEnum = 68613\n",
    "scores_fg = funcEnum_2_scores_dict_fg[funcEnum]\n",
    "scores_bg = funcEnum_2_scores_dict_bg[funcEnum]\n",
    "print(stats.ks_2samp(scores_fg, scores_bg, alternative=\"two-sided\", mode=\"exact\"))\n",
    "scores_fg, scores_bg = transformation_to_randomize_sort_order(scores_fg, scores_bg)\n",
    "print(stats.ks_2samp(scores_fg, scores_bg, alternative=\"two-sided\", mode=\"exact\"))\n",
    "print(stats.ks_2samp(data1, data2, alternative=\"two-sided\", mode=\"exact\"))\n",
    "data1, data2 = transformation_to_randomize_sort_order(data1, data2)\n",
    "print(stats.ks_2samp(data1, data2, alternative=\"two-sided\", mode=\"exact\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "dfx = pd.DataFrame()\n",
    "dfx[\"bg\"] = pd.Series(scores_bg)\n",
    "dfx[\"bg\"].hist(cumulative=True, density=1, bins=100, alpha=0.2)\n",
    "dfx[\"fg\"] = pd.Series(scores_fg)\n",
    "dfx[\"fg\"].hist(cumulative=True, density=1, bins=100, alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fg_and_bg_2_DF_melt_and_add_ranks(fg, bg):\n",
    "    dfx = pd.DataFrame()\n",
    "    dfx[\"bg\"] = pd.Series(bg)\n",
    "    dfx[\"fg\"] = pd.Series(fg)\n",
    "    # transform dataframe to long format\n",
    "    dfxm = dfx.melt(value_vars=[\"fg\", \"bg\"], var_name=\"FG_BG\", value_name=\"score\")\n",
    "    dfxm = dfxm[dfxm[\"score\"].notnull()]\n",
    "    dfxm = dfxm.sort_values([\"score\", \"FG_BG\"], ascending=[True, False]).reset_index(drop=True)\n",
    "    dfxm[\"rank\"] = dfxm[\"score\"].rank(method=\"first\")\n",
    "    return dfxm\n",
    "# scores_fg = funcEnum_2_scores_dict_fg[funcEnum]\n",
    "# scores_bg = funcEnum_2_scores_dict_bg[funcEnum]\n",
    "# dfxm = fg_and_bg_2_DF_melt_and_add_ranks(scores_fg, scores_bg)\n",
    "# print(stats.ks_2samp(scores_fg, scores_bg, alternative=\"two-sided\", mode=\"exact\"))\n",
    "# stats.ks_2samp(dfxm.loc[dfxm[\"FG_BG\"] == \"fg\", \"score\"].to_list(), dfxm.loc[dfxm[\"FG_BG\"] == \"bg\", \"score\"].to_list(), alternative=\"two-sided\", mode=\"exact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores_fg = funcEnum_2_scores_dict_fg[funcEnum]\n",
    "# sorted(scores_fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Print profiling statistics using the `line_profiler` API\n",
    "### 'run_cythonized.run_genome_cy(taxid, protein_ans, background_n, preloaded_objects_per_analysis, static_preloaded_objects, args_dict, low_memory=False)'\n",
    "profile = line_profiler.LineProfiler(run_genome_cy)\n",
    "profile.runcall(run_genome_cy, taxid, protein_ans, background_n, preloaded_objects_per_analysis, static_preloaded_objects, args_dict, low_memory=False)\n",
    "profile.print_stats()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python agotool",
   "language": "python",
   "name": "agotool"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "182px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
